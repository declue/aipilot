"""
ë‹¤ë‹¨ê³„ ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš°
ë³µì¡í•œ ìš”ì²­ì„ ì—¬ëŸ¬ ë‹¨ê³„ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
"""

import logging
from typing import Any, Callable, Dict, Optional

from application.llm.workflow.base_workflow import BaseWorkflow
from application.util.logger import setup_logger

logger = setup_logger(__name__) or logging.getLogger(__name__)


class MultiStepWorkflow(BaseWorkflow):
    """ë‹¤ë‹¨ê³„ ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš°"""

    def __init__(self):
        self.steps = []
        self.step_results = {}

    async def run(
        self, agent: Any, message: str, streaming_callback: Optional[Callable[[str], None]] = None
    ) -> str:
        """
        ë‹¤ë‹¨ê³„ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰

        Args:
            agent: LLM ì—ì´ì „íŠ¸
            message: ì²˜ë¦¬í•  ë©”ì‹œì§€
            streaming_callback: ìŠ¤íŠ¸ë¦¬ë° ì½œë°±

        Returns:
            str: ì²˜ë¦¬ ê²°ê³¼
        """
        try:
            logger.info(f"ë‹¤ë‹¨ê³„ ì›Œí¬í”Œë¡œìš° ì‹œì‘: {message[:50]}...")

            # 1ë‹¨ê³„: ì‘ì—… ë¶„í•´
            task_breakdown = await self._break_down_task(agent, message, streaming_callback)
            
            # 2ë‹¨ê³„: ê° í•˜ìœ„ ì‘ì—… ì‹¤í–‰
            results = await self._execute_subtasks(agent, task_breakdown, streaming_callback)
            
            # 3ë‹¨ê³„: ê²°ê³¼ í†µí•©
            final_result = await self._integrate_results(agent, message, results, streaming_callback)

            logger.info("ë‹¤ë‹¨ê³„ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ")
            return final_result

        except Exception as e:
            logger.error(f"ë‹¤ë‹¨ê³„ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return f"ë‹¤ë‹¨ê³„ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    async def _break_down_task(
        self, agent: Any, message: str, streaming_callback: Optional[Callable[[str], None]] = None
    ) -> Dict[str, str]:
        """ì‘ì—…ì„ í•˜ìœ„ ì‘ì—…ë“¤ë¡œ ë¶„í•´"""
        breakdown_prompt = f"""
        ë‹¤ìŒ ë³µì¡í•œ ìš”ì²­ì„ ë…¼ë¦¬ì ì¸ ë‹¨ê³„ë“¤ë¡œ ë¶„í•´í•´ì£¼ì„¸ìš”:

        ìš”ì²­: {message}

        ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
        {{
            "step_1": "ì²« ë²ˆì§¸ ë‹¨ê³„ ì„¤ëª…",
            "step_2": "ë‘ ë²ˆì§¸ ë‹¨ê³„ ì„¤ëª…",
            "step_3": "ì„¸ ë²ˆì§¸ ë‹¨ê³„ ì„¤ëª…",
            ...
        }}

        ê° ë‹¨ê³„ëŠ”:
        - ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•´ì•¼ í•¨
        - ëª…í™•í•œ ëª©ì ì„ ê°€ì ¸ì•¼ í•¨
        - ìˆœì„œëŒ€ë¡œ ì‹¤í–‰ë˜ì–´ì•¼ í•¨
        - 3-7ê°œ ë‹¨ê³„ë¡œ ë¶„í•´í•´ì£¼ì„¸ìš”

        JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
        """

        if streaming_callback:
            streaming_callback("ğŸ”„ ì‘ì—… ë¶„í•´ ì¤‘...\n\n")

        if hasattr(agent, "_generate_basic_response"):
            response = await agent._generate_basic_response(breakdown_prompt, streaming_callback)
        else:
            response = '{"step_1": "ì‘ì—… ë¶„í•´ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}'

        # JSON íŒŒì‹± ì‹œë„
        try:
            import json

            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
            start_idx = response.find("{")
            end_idx = response.rfind("}") + 1
            if start_idx != -1 and end_idx != 0:
                json_str = response[start_idx:end_idx]
                breakdown = json.loads(json_str)
            else:
                breakdown = {"step_1": "ì‘ì—… ë¶„í•´ íŒŒì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤"}
        except Exception as e:
            logger.warning(f"ì‘ì—… ë¶„í•´ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨: {e}")
            breakdown = {"step_1": "ì‘ì—… ë¶„í•´ ê²°ê³¼ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}

        logger.debug(f"ì‘ì—… ë¶„í•´ ì™„ë£Œ: {len(breakdown)}ê°œ ë‹¨ê³„")
        return breakdown

    async def _execute_subtasks(
        self,
        agent: Any,
        task_breakdown: Dict[str, str],
        streaming_callback: Optional[Callable[[str], None]] = None,
    ) -> Dict[str, str]:
        """ê° í•˜ìœ„ ì‘ì—…ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰"""
        results = {}
        
        for step_name, step_description in task_breakdown.items():
            if streaming_callback:
                streaming_callback(f"âš™ï¸ {step_name} ì‹¤í–‰ ì¤‘...\n\n")

            # ì´ì „ ë‹¨ê³„ ê²°ê³¼ë“¤ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ í¬í•¨
            context = self._build_context(results)
            
            step_prompt = f"""
            ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:

            ë‹¨ê³„: {step_name}
            ì„¤ëª…: {step_description}

            ì´ì „ ë‹¨ê³„ ê²°ê³¼ë“¤:
            {context}

            ì´ ë‹¨ê³„ì—ì„œ ìˆ˜í–‰í•´ì•¼ í•  ì‘ì—…ì„ ì •í™•íˆ ìˆ˜í–‰í•˜ê³ , 
            ë‹¤ìŒ ë‹¨ê³„ì—ì„œ í™œìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ê²°ê³¼ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.
            """

            try:
                # MCP ë„êµ¬ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° í™œìš©
                if hasattr(agent, "mcp_tool_manager") and agent.mcp_tool_manager:
                    if hasattr(agent, "generate_response"):
                        result = await agent.generate_response(step_prompt, streaming_callback)
                        step_result = result.get("response", f"{step_name} ì‹¤í–‰ ì‹¤íŒ¨")
                    else:
                        step_result = await self._execute_basic_step(agent, step_prompt, streaming_callback)
                else:
                    step_result = await self._execute_basic_step(agent, step_prompt, streaming_callback)
                
                results[step_name] = step_result
                logger.debug(f"{step_name} ì™„ë£Œ")
                
            except Exception as e:
                logger.error(f"{step_name} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
                results[step_name] = f"{step_name} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

        return results

    async def _execute_basic_step(
        self, agent: Any, prompt: str, streaming_callback: Optional[Callable[[str], None]] = None
    ) -> str:
        """ê¸°ë³¸ ë‹¨ê³„ ì‹¤í–‰"""
        if hasattr(agent, "_generate_basic_response"):
            return await agent._generate_basic_response(prompt, streaming_callback)
        else:
            return "ê¸°ë³¸ ë‹¨ê³„ ì‹¤í–‰ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"

    def _build_context(self, results: Dict[str, str]) -> str:
        """ì´ì „ ë‹¨ê³„ ê²°ê³¼ë“¤ë¡œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        if not results:
            return "(ì´ì „ ë‹¨ê³„ ê²°ê³¼ ì—†ìŒ)"
        
        context_parts = []
        for step_name, result in results.items():
            context_parts.append(f"- {step_name}: {result[:200]}...")
        
        return "\n".join(context_parts)

    async def _integrate_results(
        self,
        agent: Any,
        original_message: str,
        results: Dict[str, str],
        streaming_callback: Optional[Callable[[str], None]] = None,
    ) -> str:
        """ê²°ê³¼ í†µí•© ë° ìµœì¢… ì‘ë‹µ ìƒì„±"""
        integration_prompt = f"""
        ì›ë˜ ìš”ì²­: {original_message}

        ê° ë‹¨ê³„ë³„ ê²°ê³¼:
        {self._format_results(results)}

        ìœ„ ë‹¨ê³„ë³„ ê²°ê³¼ë“¤ì„ ì¢…í•©í•˜ì—¬ ì›ë˜ ìš”ì²­ì— ëŒ€í•œ ì™„ì „í•˜ê³  ì¼ê´€ì„± ìˆëŠ” ìµœì¢… ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

        ìµœì¢… ë‹µë³€ì€:
        1. ëª¨ë“  ë‹¨ê³„ì˜ ê²°ê³¼ë¥¼ í†µí•©í•´ì•¼ í•¨
        2. ì›ë˜ ìš”ì²­ì„ ì™„ì „íˆ ë§Œì¡±í•´ì•¼ í•¨
        3. ë…¼ë¦¬ì ì´ê³  ì¼ê´€ì„± ìˆì–´ì•¼ í•¨
        4. ì‹¤ìš©ì ì´ê³  ìœ ìš©í•´ì•¼ í•¨

        ì „ë¬¸ì ì´ê³  ì™„ì„±ë„ ë†’ì€ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
        """

        if streaming_callback:
            streaming_callback("ğŸ”§ ê²°ê³¼ í†µí•© ì¤‘...\n\n")

        if hasattr(agent, "_generate_basic_response"):
            final_result = await agent._generate_basic_response(integration_prompt, streaming_callback)
        else:
            final_result = "ê²°ê³¼ í†µí•© ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"

        logger.debug("ê²°ê³¼ í†µí•© ì™„ë£Œ")
        return final_result

    def _format_results(self, results: Dict[str, str]) -> str:
        """ê²°ê³¼ë¥¼ í¬ë§·íŒ…"""
        formatted_parts = []
        for step_name, result in results.items():
            formatted_parts.append(f"**{step_name}:**\n{result}\n")
        
        return "\n".join(formatted_parts) 