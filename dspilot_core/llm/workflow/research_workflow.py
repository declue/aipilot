"""
ì „ë¬¸ ë¦¬ì„œì¹˜ ì›Œí¬í”Œë¡œìš° (ResearchWorkflow)
========================================

Perplexity ìŠ¤íƒ€ì¼ì˜ ì‹¬ì¸µì ì´ê³  ì „ë¬¸ì ì¸ ì¡°ì‚¬ ë° ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” ì›Œí¬í”Œë¡œìš°ì…ë‹ˆë‹¤.
ì‹¤ì‹œê°„ ì›¹ê²€ìƒ‰ì„ í†µí•´ ë‹¤ê°ë„ë¡œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³ , ê²€ì¦ì„ ê±°ì³ ì¢…í•©ì ì¸ ë¦¬ì„œì¹˜ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

ë‹¨ìˆœí•œ ê²€ìƒ‰ì„ ë„˜ì–´ì„œ ì „ë¬¸ì ì¸ ì¡°ì‚¬ ë°©ë²•ë¡ ì„ ì ìš©í•˜ì—¬, ì‹ ë¢°ì„± ìˆê³  
í¬ê´„ì ì¸ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ê²ƒì´ íŠ¹ì§•ì…ë‹ˆë‹¤.

ì£¼ìš” íŠ¹ì§•
=========

1. **ë‹¤ê°ë„ ê²€ìƒ‰ ì „ëµ**
   - ì£¼ì œë¥¼ ì—¬ëŸ¬ ê´€ì ì—ì„œ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
   - ê¸°ë³¸ ê°œë…, ìµœì‹  ë™í–¥, ì „ë¬¸ê°€ ì˜ê²¬, í†µê³„ ë°ì´í„° ë“± í¬ê´„ì  ìˆ˜ì§‘
   - ì¤‘ë³µ ì—†ì´ ì„œë¡œ ë‹¤ë¥¸ ê´€ì ì˜ ì •ë³´ í™•ë³´

2. **ì‹¬ì¸µ ë¶„ì„ í”„ë¡œì„¸ìŠ¤**
   - ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ í›„ ì¶”ê°€ ì¡°ì‚¬ ì˜ì—­ ì‹ë³„
   - ë°ì´í„° ë¶€ì¡± ì˜ì—­ì´ë‚˜ ìƒì¶© ì •ë³´ì— ëŒ€í•œ ì¶”ê°€ ê²€ìƒ‰
   - ì •ë³´ì˜ ì‹ ë¢°ì„± ë° ìµœì‹ ì„± í‰ê°€

3. **ì „ë¬¸ì  ë³´ê³ ì„œ ìƒì„±**
   - Perplexity ìŠ¤íƒ€ì¼ì˜ êµ¬ì¡°í™”ëœ ë¦¬ì„œì¹˜ ë³´ê³ ì„œ
   - í•µì‹¬ ìš”ì•½, ì£¼ìš” ë°œê²¬ì‚¬í•­, ì‹¬ì¸µ ë¶„ì„, ì‹œì‚¬ì  ë“± í¬í•¨
   - ì¶œì²˜ ì •ë³´ ë° ì œí•œì‚¬í•­ ëª…ì‹œ

4. **ì •ë³´ ê²€ì¦ ì‹œìŠ¤í…œ**
   - ìˆ˜ì§‘ëœ ì •ë³´ì˜ ì‹ ë¢°ì„± í‰ê°€ (1-10ì  ì²™ë„)
   - ì •ë³´ ê°„ ì¼ê´€ì„± í™•ì¸ ë° ìƒì¶© ë‚´ìš© ì‹ë³„
   - ì‚¬ì‹¤ í™•ì¸ì´ í•„ìš”í•œ ì£¼ì¥ë“¤ ë³„ë„ í‘œì‹œ

ì²˜ë¦¬ ê³¼ì • ë‹¤ì´ì–´ê·¸ë¨
==================

```mermaid
flowchart TD
    A[ë¦¬ì„œì¹˜ ì£¼ì œ] --> B[ë‹¤ê°ë„ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±]
    B --> C[ì›¹ê²€ìƒ‰ ì‹¤í–‰ ë° ì •ë³´ ìˆ˜ì§‘]
    C --> D[ì´ˆê¸° ê²°ê³¼ ë¶„ì„]
    D --> E{ì¶”ê°€ ì¡°ì‚¬ í•„ìš”?}
    E -->|Yes| F[ì‹¬í™” ê²€ìƒ‰ ì‹¤í–‰]
    E -->|No| G[ì •ë³´ ê²€ì¦ ë° ì‹ ë¢°ì„± í‰ê°€]
    F --> G
    G --> H[ì¢…í•© ë¦¬ì„œì¹˜ ë³´ê³ ì„œ ìƒì„±]
    H --> I[ìµœì¢… ë³´ê³ ì„œ ë°˜í™˜]
```

ë¦¬ì„œì¹˜ ë‹¨ê³„ë³„ ì„¸ë¶€ ê³¼ì •
=====================

### 1ë‹¨ê³„: ë‹¤ê°ë„ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
**ëª©ì **: ì£¼ì œë¥¼ í¬ê´„ì ìœ¼ë¡œ ì¡°ì‚¬í•˜ê¸° ìœ„í•œ ë‹¤ì–‘í•œ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±

**ìƒì„± ê´€ì **:
- ê¸°ë³¸ ê°œë… ë° ì •ì˜
- ìµœì‹  ë™í–¥ ë° ë‰´ìŠ¤  
- ì „ë¬¸ê°€ ì˜ê²¬ ë° ë¶„ì„
- í†µê³„ ë° ë°ì´í„°
- ê´€ë ¨ ì¼€ì´ìŠ¤ ìŠ¤í„°ë””
- ë¹„êµ ë¶„ì„ (ê²½ìŸì‚¬, ëŒ€ì•ˆ ë“±)
- ë¯¸ë˜ ì „ë§ ë° ì˜ˆì¸¡

**ì˜ˆì‹œ**: "ì¸ê³µì§€ëŠ¥ ìœ¤ë¦¬" ì£¼ì œì˜ ê²½ìš°
- "AI ethics definition principles"
- "ì¸ê³µì§€ëŠ¥ ìœ¤ë¦¬ ìµœì‹  ë™í–¥ 2024"
- "AI ethics expert opinion analysis"
- "artificial intelligence ethics statistics data"
- "AI ethics case study examples"

### 2ë‹¨ê³„: ì›¹ê²€ìƒ‰ ì‹¤í–‰ ë° ì •ë³´ ìˆ˜ì§‘
**í”„ë¡œì„¸ìŠ¤**:
- ê° ê²€ìƒ‰ ì¿¼ë¦¬ë³„ë¡œ MCP ì›¹ê²€ìƒ‰ ë„êµ¬ ì‚¬ìš©
- ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ì§‘ ë° ì„ì‹œ ì €ì¥
- ì‹¤íŒ¨í•œ ê²€ìƒ‰ì— ëŒ€í•œ ì˜¤ë¥˜ ë¡œê¹…
- ìŠ¤íŠ¸ë¦¬ë° ì½œë°±ì„ í†µí•œ ì§„í–‰ ìƒí™© ì‹¤ì‹œê°„ í”¼ë“œë°±

### 3ë‹¨ê³„: ì¶”ê°€ ì‹¬í™” ê²€ìƒ‰
**íŒë‹¨ ê¸°ì¤€**:
- ë°ì´í„° ë¶€ì¡± ì˜ì—­ ì‹ë³„
- ìƒì¶©ë˜ëŠ” ì •ë³´ ë°œê²¬ ì‹œ
- ë” ê¹Šì´ íŒŒì•¼ í•  ì „ë¬¸ ë¶„ì•¼ ì¡´ì¬
- ìµœì‹  ì—…ë°ì´íŠ¸ê°€ í•„ìš”í•œ ë¶€ë¶„

**ì‹¤í–‰ ë°©ì‹**:
- LLMì´ ì´ˆê¸° ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ì¶”ê°€ ê²€ìƒ‰ í•„ìš”ì„± íŒë‹¨
- í•„ìš”ì‹œ 2-3ê°œì˜ ì¶”ê°€ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ë° ì‹¤í–‰

### 4ë‹¨ê³„: ì •ë³´ ê²€ì¦ ë° ì‹ ë¢°ì„± í‰ê°€
**í‰ê°€ ê¸°ì¤€**:
- ì •ë³´ì˜ ì‹ ë¢°ì„± (1-10ì ): ì¶œì²˜ì˜ ê¶Œìœ„ì„±, ì •ë³´ì˜ ì •í™•ì„±
- ì •ë³´ì˜ ìµœì‹ ì„± (1-10ì ): ë°œí–‰ì¼, ì—…ë°ì´íŠ¸ ë¹ˆë„
- ì¶œì²˜ì˜ ê¶Œìœ„ì„± (1-10ì ): ê¸°ê´€ì˜ ì‹ ë¢°ë„, ì „ë¬¸ì„±
- ì •ë³´ ê°„ ì¼ê´€ì„±: ì—¬ëŸ¬ ì†ŒìŠ¤ ê°„ ë‚´ìš© ì¼ì¹˜ë„

### 5ë‹¨ê³„: ì¢…í•© ë¦¬ì„œì¹˜ ë³´ê³ ì„œ ìƒì„±
**ë³´ê³ ì„œ êµ¬ì¡°**:
```
# ì£¼ì œëª…

## ğŸ” í•µì‹¬ ìš”ì•½
- 3-4ì¤„ í•µì‹¬ ë‚´ìš© ìš”ì•½
- ê°€ì¥ ì¤‘ìš”í•œ ë°œê²¬ì‚¬í•­

## ğŸ“Š ì£¼ìš” ë°œê²¬ì‚¬í•­  
1. ì²« ë²ˆì§¸ í•µì‹¬ ë°œê²¬ (êµ¬ì²´ì  ë°ì´í„° + ì¶œì²˜)
2. ë‘ ë²ˆì§¸ í•µì‹¬ ë°œê²¬ (êµ¬ì²´ì  ë°ì´í„° + ì¶œì²˜)
3. ì„¸ ë²ˆì§¸ í•µì‹¬ ë°œê²¬ (êµ¬ì²´ì  ë°ì´í„° + ì¶œì²˜)

## ğŸ§­ ì‹¬ì¸µ ë¶„ì„
- ë°ì´í„° ê°„ ì—°ê´€ì„± ë¶„ì„
- íŒ¨í„´ê³¼ íŠ¸ë Œë“œ ì‹ë³„  
- ì „ë¬¸ê°€ ê´€ì  ì¢…í•©

## ğŸ”® ì‹œì‚¬ì  ë° ì „ë§
- í˜„ì¬ ìƒí™©ì˜ ì˜ë¯¸
- ë¯¸ë˜ ì „ë§
- ì£¼ì˜í•  ì 

## âš ï¸ ì œí•œì‚¬í•­
- ì •ë³´ì˜ í•œê³„ì 
- ì¶”ê°€ ì¡°ì‚¬ í•„ìš” ì˜ì—­
- ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„

## ğŸ“š ì°¸ê³  ì •ë³´
- ì£¼ìš” ì¶œì²˜ë“¤
- ê´€ë ¨ ë¦¬ì†ŒìŠ¤
```

ì‚¬ìš© ê¶Œì¥ ìƒí™©
=============

### ì í•©í•œ ì‚¬ìš© ì‚¬ë¡€:
- **í•™ìˆ  ì—°êµ¬**: ë…¼ë¬¸ ì‘ì„±, ë¬¸í—Œ ì¡°ì‚¬, í˜„í™© ë¶„ì„
- **ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„**: ì‹œì¥ ì¡°ì‚¬, ê²½ìŸì‚¬ ë¶„ì„, íŠ¸ë Œë“œ ë¶„ì„
- **ì •ì±… ì—°êµ¬**: ì‚¬íšŒ ì´ìŠˆ ë¶„ì„, ì •ì±… íš¨ê³¼ ì¡°ì‚¬
- **ê¸°ìˆ  ì¡°ì‚¬**: ì‹ ê¸°ìˆ  ë™í–¥, ê¸°ìˆ  ë¹„êµ ë¶„ì„
- **íˆ¬ì ë¶„ì„**: ì‚°ì—… ì „ë§, ê¸°ì—… ë¶„ì„, ë¦¬ìŠ¤í¬ í‰ê°€

### ë¶€ì í•©í•œ ì‚¬ìš© ì‚¬ë¡€:
- **ë‹¨ìˆœ ì •ë³´ ì¡°íšŒ**: ë‚ ì”¨, ì‹œê°„ ë“± ê°„ë‹¨í•œ ì •ë³´
- **ê°œì¸ì  ì§ˆë¬¸**: ê°œì¸ ìƒë‹´, ê°„ë‹¨í•œ ë„ì›€ë§
- **ì¦‰ì‹œ ë‹µë³€ í•„ìš”**: ê¸´ê¸‰í•œ ì˜ì‚¬ê²°ì •, ì‹¤ì‹œê°„ ëŒ€ì‘
- **ë„êµ¬ ì—†ëŠ” í™˜ê²½**: ì›¹ê²€ìƒ‰ ë„êµ¬ê°€ ì—†ëŠ” ê²½ìš°

ì‚¬ìš©ë²• ë° ì˜ˆì‹œ
=============

### 1. ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from dspilot_core.llm.workflow import ResearchWorkflow

# ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™”
workflow = ResearchWorkflow()

# ë¦¬ì„œì¹˜ ì‹¤í–‰
result = await workflow.run(
    agent=agent,
    message="ì¸ê³µì§€ëŠ¥ì´ êµìœ¡ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì— ëŒ€í•´ ì¡°ì‚¬í•´ì£¼ì„¸ìš”",
    streaming_callback=progress_callback
)
```

### 2. ì—ì´ì „íŠ¸ì—ì„œ ì‚¬ìš©

```python
class ProblemAgent(BaseAgent):
    def _get_workflow_name(self, mode: str) -> str:
        if mode == "research":
            return "research"  # ResearchWorkflow ì‚¬ìš©
        # ... ë‹¤ë¥¸ ëª¨ë“œë“¤
```

### 3. ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§

```python
def research_progress(content: str):
    if "ê²€ìƒ‰" in content:
        print(f"ğŸ” {content}")
    elif "ë¶„ì„" in content:
        print(f"ğŸ§  {content}")
    elif "ë³´ê³ ì„œ" in content:
        print(f"ğŸ“ {content}")

result = await workflow.run(agent, research_topic, research_progress)
```

ì„±ëŠ¥ ë° í’ˆì§ˆ íŠ¹ì„±
================

### ì¥ì 
- **í¬ê´„ì„±**: ë‹¤ê°ë„ ê²€ìƒ‰ìœ¼ë¡œ ë¹ ëœ¨ë¦¬ëŠ” ì •ë³´ ìµœì†Œí™”
- **ì‹ ë¢°ì„±**: ì •ë³´ ê²€ì¦ ë° ì¶œì²˜ í‰ê°€ ì‹œìŠ¤í…œ
- **ì „ë¬¸ì„±**: ì²´ê³„ì ì¸ ì¡°ì‚¬ ë°©ë²•ë¡  ì ìš©
- **êµ¬ì¡°í™”**: ì½ê¸° ì‰½ê³  í™œìš©í•˜ê¸° ì¢‹ì€ ë³´ê³ ì„œ í˜•ì‹

### ì œí•œì‚¬í•­
- **ì‹œê°„ ì†Œìš”**: ë‹¤ë‹¨ê³„ ê²€ìƒ‰ìœ¼ë¡œ ì¸í•œ ì²˜ë¦¬ ì‹œê°„ ì¦ê°€
- **ë„êµ¬ ì˜ì¡´**: ì›¹ê²€ìƒ‰ ë„êµ¬ ì—†ì´ëŠ” ê¸°ë³¸ ì§€ì‹ ê¸°ë°˜ìœ¼ë¡œë§Œ ë™ì‘
- **ë¹„ìš©**: ì—¬ëŸ¬ ë²ˆì˜ LLM í˜¸ì¶œë¡œ ì¸í•œ API ë¹„ìš© ì¦ê°€
- **ì–¸ì–´ ì œí•œ**: ì£¼ë¡œ í•œêµ­ì–´/ì˜ì–´ ì†ŒìŠ¤ì— ì˜ì¡´

ìµœì í™” íŒ
=========

### íš¨ê³¼ì ì¸ ë¦¬ì„œì¹˜ ì£¼ì œ ì„¤ì •
1. **êµ¬ì²´ì  ì£¼ì œ**: "AI ê¸°ìˆ "ë³´ë‹¤ëŠ” "ì˜ë£Œ ë¶„ì•¼ AI í™œìš© í˜„í™©"
2. **ëª…í™•í•œ ë²”ìœ„**: "ê¸€ë¡œë²Œ ë™í–¥" vs "êµ­ë‚´ í˜„í™©" ë“± ë²”ìœ„ ëª…ì‹œ
3. **ì‹œê°„ ë²”ìœ„**: "ìµœê·¼ 3ë…„ê°„", "2024ë…„ í˜„ì¬" ë“± ì‹œì  ëª…ì‹œ

### í’ˆì§ˆ í–¥ìƒ ë°©ë²•
- ì‹ ë¢°í•  ë§Œí•œ ì¶œì²˜ê°€ ë§ì€ ì£¼ì œ ì„ íƒ
- ë„ˆë¬´ ìƒˆë¡œìš´ ì£¼ì œë³´ë‹¤ëŠ” ì–´ëŠ ì •ë„ ì •ë³´ê°€ ì¶•ì ëœ ì£¼ì œ
- ê°ê´€ì  ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ” ì£¼ì œ ìš°ì„ 

ë¬¸ì œ í•´ê²°
=========

### MCP ë„êµ¬ ì—†ëŠ” ê²½ìš°
- ìë™ìœ¼ë¡œ ê¸°ë³¸ ì§€ì‹ ê¸°ë°˜ ë¶„ì„ìœ¼ë¡œ í´ë°±
- ì œí•œì ì´ì§€ë§Œ ê¸°ë³¸ì ì¸ ë¶„ì„ ì •ë³´ ì œê³µ
- ì¶”ì²œ ê²€ìƒ‰ í‚¤ì›Œë“œ ì œê³µ

### ê²€ìƒ‰ ê²°ê³¼ ë¶€ì¡±
- ë‹¤ì–‘í•œ í‚¤ì›Œë“œë¡œ ì¬ê²€ìƒ‰ ì‹œë„
- ê´€ë ¨ ì£¼ì œë¡œ ë²”ìœ„ í™•ì¥
- ë¶€ì¡±í•œ ë¶€ë¶„ì„ ëª…ì‹œì ìœ¼ë¡œ ë³´ê³ ì„œì— ê¸°ì¬

### ìƒì¶© ì •ë³´ ë°œê²¬
- ì—¬ëŸ¬ ì¶œì²˜ì˜ ì •ë³´ë¥¼ ê· í˜•ìˆê²Œ ì œì‹œ
- ìƒì¶© ë‚´ìš©ì„ ëª…í™•íˆ í‘œì‹œ
- ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•œ ë¶€ë¶„ ì•ˆë‚´

í™•ì¥ ê°€ëŠ¥ì„±
===========

### í–¥í›„ ê°œì„  ë°©í–¥
- **ë‹¤êµ­ì–´ ì§€ì›**: ë” ë§ì€ ì–¸ì–´ì˜ ì†ŒìŠ¤ í™œìš©
- **ì „ë¬¸ ë°ì´í„°ë² ì´ìŠ¤**: í•™ìˆ  DB, ì •ë¶€ í†µê³„ ë“± ì—°ë™
- **ì‹œê°í™”**: ì°¨íŠ¸, ê·¸ë˜í”„ ë“± ë°ì´í„° ì‹œê°í™” ê¸°ëŠ¥
- **í˜‘ì—… ê¸°ëŠ¥**: ì—¬ëŸ¬ ì—ì´ì „íŠ¸ ê°„ ë¦¬ì„œì¹˜ ê²°ê³¼ ê³µìœ 
"""

import logging
from typing import Any, Callable, Dict, List, Optional

from dspilot_core.llm.workflow.base_workflow import BaseWorkflow
from dspilot_core.util.logger import setup_logger

logger = setup_logger(__name__) or logging.getLogger(__name__)


class ResearchWorkflow(BaseWorkflow):
    """
    ì „ë¬¸ ë¦¬ì„œì¹˜ ì›Œí¬í”Œë¡œìš°
    
    Perplexity ìŠ¤íƒ€ì¼ì˜ ì‹¬ì¸µì ì´ê³  ì „ë¬¸ì ì¸ ì¡°ì‚¬ ë° ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    ì‹¤ì‹œê°„ ì›¹ê²€ìƒ‰ì„ í†µí•´ ë‹¤ê°ë„ë¡œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³ , ê²€ì¦ì„ ê±°ì³ 
    ì¢…í•©ì ì¸ ë¦¬ì„œì¹˜ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    ì£¼ìš” íŠ¹ì§•:
    - ë‹¤ê°ë„ ê²€ìƒ‰ ì „ëµìœ¼ë¡œ í¬ê´„ì  ì •ë³´ ìˆ˜ì§‘
    - ì •ë³´ ê²€ì¦ ë° ì‹ ë¢°ì„± í‰ê°€ ì‹œìŠ¤í…œ
    - ì „ë¬¸ì ì´ê³  êµ¬ì¡°í™”ëœ ë¦¬ì„œì¹˜ ë³´ê³ ì„œ ìƒì„±
    - ì‹¬ì¸µ ë¶„ì„ ë° ì¶”ê°€ ì¡°ì‚¬ ê¸°ëŠ¥
    
    Attributes:
        search_queries: ìƒì„±ëœ ê²€ìƒ‰ ì¿¼ë¦¬ ëª©ë¡
        collected_sources: ìˆ˜ì§‘ëœ ì •ë³´ ì†ŒìŠ¤ ëª©ë¡  
        research_depth: ë¦¬ì„œì¹˜ ê¹Šì´ ì„¤ì • ("basic", "standard", "comprehensive")
    """

    def __init__(self):
        """ResearchWorkflow ì´ˆê¸°í™”"""
        self.search_queries = []
        self.collected_sources = []
        self.research_depth = "comprehensive"  # ê¸°ë³¸ê°’: í¬ê´„ì  ì¡°ì‚¬

    async def run(
        self, agent: Any, message: str, streaming_callback: Optional[Callable[[str], None]] = None
    ) -> str:
        """
        ì „ë¬¸ ë¦¬ì„œì¹˜ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰

        ì£¼ì–´ì§„ ì£¼ì œì— ëŒ€í•´ ë‹¤ë‹¨ê³„ ë¦¬ì„œì¹˜ í”„ë¡œì„¸ìŠ¤ë¥¼ ìˆ˜í–‰í•˜ì—¬
        ì „ë¬¸ì ì´ê³  í¬ê´„ì ì¸ ì¡°ì‚¬ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            agent: LLM ì—ì´ì „íŠ¸ (MCP ì›¹ê²€ìƒ‰ ë„êµ¬ í•„ìš”)
            message: ë¦¬ì„œì¹˜ ì§ˆë¬¸/ì£¼ì œ
            streaming_callback: ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© ì½œë°±

        Returns:
            str: ì¢…í•© ë¦¬ì„œì¹˜ ë³´ê³ ì„œ ë˜ëŠ” ê¸°ë³¸ ë¶„ì„ ê²°ê³¼

        Raises:
            Exception: ë¦¬ì„œì¹˜ í”„ë¡œì„¸ìŠ¤ ì¤‘ ë³µêµ¬ ë¶ˆê°€ëŠ¥í•œ ì˜¤ë¥˜ ë°œìƒ ì‹œ
        """
        try:
            logger.info(f"ì „ë¬¸ ë¦¬ì„œì¹˜ ì›Œí¬í”Œë¡œìš° ì‹œì‘: {message[:50]}...")

            # MCP ë„êµ¬ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸
            if not hasattr(agent, "mcp_tool_manager") or not agent.mcp_tool_manager:
                logger.warning("MCP ë„êµ¬ê°€ ì—†ì–´ ê¸°ë³¸ ì§€ì‹ ê¸°ë°˜ ë¶„ì„ìœ¼ë¡œ í´ë°±")
                return await self._fallback_research(agent, message, streaming_callback)

            if streaming_callback:
                streaming_callback("ğŸ” **ì „ë¬¸ ë¦¬ì„œì¹˜ ì‹œì‘**\n\n")

            # 1ë‹¨ê³„: ë‹¤ê°ë„ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
            search_queries = await self._generate_search_queries(agent, message, streaming_callback)
            
            # 2ë‹¨ê³„: ì›¹ê²€ìƒ‰ ì‹¤í–‰ ë° ì •ë³´ ìˆ˜ì§‘
            raw_data = await self._execute_web_searches(agent, search_queries, streaming_callback)
            
            # 3ë‹¨ê³„: ì¶”ê°€ ì‹¬í™” ê²€ìƒ‰ (í•„ìš”ì‹œ)
            enhanced_data = await self._deep_dive_search(agent, message, raw_data, streaming_callback)
            
            # 4ë‹¨ê³„: ì •ë³´ ê²€ì¦ ë° ì‹ ë¢°ì„± í‰ê°€
            verified_data = await self._verify_and_validate(agent, enhanced_data, streaming_callback)
            
            # 5ë‹¨ê³„: ì¢…í•© ë¶„ì„ ë° ë³´ê³ ì„œ ìƒì„±
            final_report = await self._generate_comprehensive_report(
                agent, message, verified_data, streaming_callback
            )

            logger.info("ì „ë¬¸ ë¦¬ì„œì¹˜ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ")
            return final_report

        except Exception as e:
            logger.error(f"ì „ë¬¸ ë¦¬ì„œì¹˜ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return f"ë¦¬ì„œì¹˜ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    async def _generate_search_queries(
        self, agent: Any, topic: str, streaming_callback: Optional[Callable[[str], None]] = None
    ) -> List[str]:
        """
        ë‹¤ê°ë„ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
        
        ì£¼ì œë¥¼ ì—¬ëŸ¬ ê´€ì ì—ì„œ ë¶„ì„í•˜ì—¬ í¬ê´„ì ì¸ ì •ë³´ ìˆ˜ì§‘ì„ ìœ„í•œ
        ë‹¤ì–‘í•œ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            agent: LLM ì—ì´ì „íŠ¸
            topic: ë¦¬ì„œì¹˜ ì£¼ì œ
            streaming_callback: ì§„í–‰ ìƒí™© ì½œë°±
            
        Returns:
            List[str]: ìƒì„±ëœ ê²€ìƒ‰ ì¿¼ë¦¬ ëª©ë¡
        """
        query_prompt = f"""
        ë‹¤ìŒ ì£¼ì œì— ëŒ€í•œ ì „ë¬¸ì ì´ê³  í¬ê´„ì ì¸ ë¦¬ì„œì¹˜ë¥¼ ìœ„í•œ ê²€ìƒ‰ ì¿¼ë¦¬ë“¤ì„ ìƒì„±í•´ì£¼ì„¸ìš”:

        ì£¼ì œ: {topic}

        ë‹¤ìŒ ê´€ì ì—ì„œ 5-7ê°œì˜ ë‹¤ì–‘í•œ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”:
        1. ê¸°ë³¸ ê°œë… ë° ì •ì˜
        2. ìµœì‹  ë™í–¥ ë° ë‰´ìŠ¤
        3. ì „ë¬¸ê°€ ì˜ê²¬ ë° ë¶„ì„
        4. í†µê³„ ë° ë°ì´í„°
        5. ê´€ë ¨ ì¼€ì´ìŠ¤ ìŠ¤í„°ë””
        6. ë¹„êµ ë¶„ì„ (ê²½ìŸì‚¬, ëŒ€ì•ˆ ë“±)
        7. ë¯¸ë˜ ì „ë§ ë° ì˜ˆì¸¡

        ê° ì¿¼ë¦¬ëŠ”:
        - êµ¬ì²´ì ì´ê³  ê²€ìƒ‰ ìµœì í™”ëœ í‚¤ì›Œë“œ ì‚¬ìš©
        - ì¤‘ë³µ ì—†ì´ ì„œë¡œ ë‹¤ë¥¸ ê´€ì  í¬í•¨
        - ì˜ì–´ì™€ í•œêµ­ì–´ í˜¼ìš© ê°€ëŠ¥

        JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
        {
            "queries": [
                "ê²€ìƒ‰ì¿¼ë¦¬1",
                "ê²€ìƒ‰ì¿¼ë¦¬2",
                ...
            ]
        }
        """

        if streaming_callback:
            streaming_callback("ğŸ“ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì¤‘...\n\n")

        response = await agent._generate_basic_response(query_prompt, None)
        
        # JSON íŒŒì‹± ë° ì¿¼ë¦¬ ì¶”ì¶œ
        try:
            import json
            start_idx = response.find("{")
            end_idx = response.rfind("}") + 1
            if start_idx != -1 and end_idx != 0:
                json_str = response[start_idx:end_idx]
                query_data = json.loads(json_str)
                queries = query_data.get("queries", [])
            else:
                # JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ì¿¼ë¦¬ ìƒì„±
                queries = [topic, f"{topic} latest news", f"{topic} analysis"]
        except Exception as e:
            logger.warning(f"ê²€ìƒ‰ ì¿¼ë¦¬ íŒŒì‹± ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°ë³¸ ì¿¼ë¦¬ ìƒì„±
            queries = [topic, f"{topic} ìµœì‹  ë™í–¥", f"{topic} ë¶„ì„", f"{topic} ì „ë¬¸ê°€ ì˜ê²¬"]

        self.search_queries = queries
        logger.debug(f"ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì™„ë£Œ: {len(queries)}ê°œ")
        return queries

    async def _execute_web_searches(
        self, agent: Any, queries: List[str], streaming_callback: Optional[Callable[[str], None]] = None
    ) -> Dict[str, str]:
        """
        ì›¹ê²€ìƒ‰ ì‹¤í–‰ ë° ì •ë³´ ìˆ˜ì§‘
        
        ìƒì„±ëœ ê²€ìƒ‰ ì¿¼ë¦¬ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ì—¬ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
        ì‹¤íŒ¨í•œ ê²€ìƒ‰ë„ ë¡œê¹…í•˜ì—¬ ë‚˜ì¤‘ì— ë¶„ì„í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
        
        Args:
            agent: LLM ì—ì´ì „íŠ¸
            queries: ê²€ìƒ‰ ì¿¼ë¦¬ ëª©ë¡
            streaming_callback: ì§„í–‰ ìƒí™© ì½œë°±
            
        Returns:
            Dict[str, str]: ì¿¼ë¦¬ë³„ ê²€ìƒ‰ ê²°ê³¼
        """
        search_results = {}
        
        for i, query in enumerate(queries, 1):
            if streaming_callback:
                streaming_callback(f"ğŸŒ ê²€ìƒ‰ {i}/{len(queries)}: {query[:50]}...\n")

            try:
                # MCP ì›¹ê²€ìƒ‰ ë„êµ¬ ì‚¬ìš©
                search_prompt = f"ì›¹ì—ì„œ ë‹¤ìŒì— ëŒ€í•´ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•´ì£¼ì„¸ìš”: {query}"
                
                if hasattr(agent, "generate_response"):
                    result = await agent.generate_response(search_prompt, None)
                    search_content = result.get("response", "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                else:
                    search_content = await agent._generate_basic_response(search_prompt, None)
                
                search_results[f"query_{i}_{query[:30]}"] = search_content
                logger.debug(f"ê²€ìƒ‰ ì™„ë£Œ: {query[:30]}...")
                
            except Exception as e:
                logger.warning(f"ê²€ìƒ‰ ì‹¤íŒ¨ - {query}: {e}")
                search_results[f"query_{i}_{query[:30]}"] = f"ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}"

        if streaming_callback:
            successful_searches = len([r for r in search_results.values() if not r.startswith("ê²€ìƒ‰ ì‹¤íŒ¨")])
            streaming_callback(f"âœ… ì´ {successful_searches}/{len(search_results)}ê°œ ê²€ìƒ‰ ì™„ë£Œ\n\n")

        return search_results

    async def _deep_dive_search(
        self, agent: Any, original_topic: str, initial_data: Dict[str, str], 
        streaming_callback: Optional[Callable[[str], None]] = None
    ) -> Dict[str, str]:
        """
        ì‹¬í™” ê²€ìƒ‰ ì‹¤í–‰
        
        ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ì¶”ê°€ ì¡°ì‚¬ê°€ í•„ìš”í•œ ì˜ì—­ì„ ì‹ë³„í•˜ê³ 
        í•„ìš”ì‹œ ì¶”ê°€ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Args:
            agent: LLM ì—ì´ì „íŠ¸
            original_topic: ì›ë˜ ë¦¬ì„œì¹˜ ì£¼ì œ
            initial_data: ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼
            streaming_callback: ì§„í–‰ ìƒí™© ì½œë°±
            
        Returns:
            Dict[str, str]: ì´ˆê¸° ë°ì´í„° + ì¶”ê°€ ê²€ìƒ‰ ê²°ê³¼
        """
        analysis_prompt = f"""
        ì›ë˜ ì£¼ì œ: {original_topic}
        
        ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ë“¤ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ ì‹ë³„í•´ì£¼ì„¸ìš”:
        {self._format_search_data(initial_data)}

        ë‹¤ìŒ ì¤‘ ì¶”ê°€ ì¡°ì‚¬ê°€ í•„ìš”í•œ ì˜ì—­ì´ ìˆë‹¤ë©´ 2-3ê°œì˜ ì¶”ê°€ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”:
        1. ë°ì´í„° ë¶€ì¡± ì˜ì—­
        2. ìƒì¶©ë˜ëŠ” ì •ë³´ê°€ ìˆëŠ” ë¶€ë¶„
        3. ë” ê¹Šì´ íŒŒì•¼ í•  ì „ë¬¸ ë¶„ì•¼
        4. ìµœì‹  ì—…ë°ì´íŠ¸ê°€ í•„ìš”í•œ ë¶€ë¶„

        JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
        {
            "need_additional_search": true/false,
            "additional_queries": ["ì¿¼ë¦¬1", "ì¿¼ë¦¬2", "ì¿¼ë¦¬3"],
            "reason": "ì¶”ê°€ ê²€ìƒ‰ì´ í•„ìš”í•œ ì´ìœ "
        }
        """

        if streaming_callback:
            streaming_callback("ğŸ”¬ ì‹¬í™” ë¶„ì„ ì¤‘...\n")

        response = await agent._generate_basic_response(analysis_prompt, None)
        
        try:
            import json
            start_idx = response.find("{")
            end_idx = response.rfind("}") + 1
            if start_idx != -1 and end_idx != 0:
                json_str = response[start_idx:end_idx]
                analysis = json.loads(json_str)
                
                if analysis.get("need_additional_search", False):
                    additional_queries = analysis.get("additional_queries", [])
                    reason = analysis.get("reason", "")
                    
                    if streaming_callback:
                        streaming_callback(f"ğŸ¯ ì¶”ê°€ ì‹¬í™” ê²€ìƒ‰ ì‹¤í–‰: {len(additional_queries)}ê°œ\n")
                        streaming_callback(f"ì‚¬ìœ : {reason}\n\n")
                    
                    logger.info(f"ì¶”ê°€ ê²€ìƒ‰ ì‹¤í–‰: {reason}")
                    additional_results = await self._execute_web_searches(
                        agent, additional_queries, streaming_callback
                    )
                    
                    # ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•©
                    enhanced_data = {**initial_data, **additional_results}
                    return enhanced_data
                else:
                    if streaming_callback:
                        streaming_callback("âœ… ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ê°€ ì¶©ë¶„í•˜ì—¬ ì¶”ê°€ ê²€ìƒ‰ ìƒëµ\n\n")
                    
        except Exception as e:
            logger.warning(f"ì‹¬í™” ê²€ìƒ‰ ë¶„ì„ ì‹¤íŒ¨: {e}")

        return initial_data

    async def _verify_and_validate(
        self, agent: Any, data: Dict[str, str], streaming_callback: Optional[Callable[[str], None]] = None
    ) -> Dict[str, Any]:
        """
        ì •ë³´ ê²€ì¦ ë° ì‹ ë¢°ì„± í‰ê°€
        
        ìˆ˜ì§‘ëœ ì •ë³´ì˜ ì‹ ë¢°ì„±, ìµœì‹ ì„±, ê¶Œìœ„ì„±ì„ í‰ê°€í•˜ê³ 
        ì •ë³´ ê°„ ì¼ê´€ì„±ì„ í™•ì¸í•©ë‹ˆë‹¤.
        
        Args:
            agent: LLM ì—ì´ì „íŠ¸
            data: ìˆ˜ì§‘ëœ ê²€ìƒ‰ ë°ì´í„°
            streaming_callback: ì§„í–‰ ìƒí™© ì½œë°±
            
        Returns:
            Dict[str, Any]: ê²€ì¦ëœ ë°ì´í„°ì™€ ë¶„ì„ ê²°ê³¼
        """
        validation_prompt = f"""
        ë‹¤ìŒ ê²€ìƒ‰ ê²°ê³¼ë“¤ì˜ ì‹ ë¢°ì„±ì„ í‰ê°€í•˜ê³  ê²€ì¦í•´ì£¼ì„¸ìš”:

        {self._format_search_data(data)}

        ê° ì •ë³´ì— ëŒ€í•´ ë‹¤ìŒì„ í‰ê°€í•´ì£¼ì„¸ìš”:
        1. ì •ë³´ì˜ ì‹ ë¢°ì„± (1-10ì )
        2. ì •ë³´ì˜ ìµœì‹ ì„± (1-10ì ) 
        3. ì¶œì²˜ì˜ ê¶Œìœ„ì„± (1-10ì )
        4. ì •ë³´ ê°„ ì¼ê´€ì„± í™•ì¸
        5. ì‚¬ì‹¤ í™•ì¸ì´ í•„ìš”í•œ ì£¼ì¥ë“¤

        ë˜í•œ ë‹¤ìŒì„ ì‹ë³„í•´ì£¼ì„¸ìš”:
        - ê°€ì¥ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ë“¤
        - ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•œ ì •ë³´ë“¤
        - ìƒì¶©ë˜ëŠ” ì •ë³´ê°€ ìˆëŠ” ê²½ìš° í•´ë‹¹ ë‚´ìš©

        ê²€ì¦ëœ í•µì‹¬ ì‚¬ì‹¤ë“¤ê³¼ ì£¼ì˜ì‚¬í•­ì„ ì •ë¦¬í•´ì£¼ì„¸ìš”.
        """

        if streaming_callback:
            streaming_callback("ğŸ” ì •ë³´ ê²€ì¦ ë° ì‹ ë¢°ì„± í‰ê°€ ì¤‘...\n")

        validation_result = await agent._generate_basic_response(validation_prompt, None)
        
        return {
            "raw_data": data,
            "validation_analysis": validation_result,
            "verified_facts": self._extract_verified_facts(validation_result)
        }

    async def _generate_comprehensive_report(
        self, agent: Any, original_question: str, verified_data: Dict[str, Any], 
        streaming_callback: Optional[Callable[[str], None]] = None
    ) -> str:
        """
        ì¢…í•© ë¦¬ì„œì¹˜ ë³´ê³ ì„œ ìƒì„±
        
        ê²€ì¦ëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ Perplexity ìŠ¤íƒ€ì¼ì˜ ì „ë¬¸ì ì¸
        ë¦¬ì„œì¹˜ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            agent: LLM ì—ì´ì „íŠ¸
            original_question: ì›ë˜ ë¦¬ì„œì¹˜ ì§ˆë¬¸
            verified_data: ê²€ì¦ëœ ë°ì´í„°
            streaming_callback: ì§„í–‰ ìƒí™© ì½œë°±
            
        Returns:
            str: ì™„ì„±ëœ ë¦¬ì„œì¹˜ ë³´ê³ ì„œ
        """
        report_prompt = f"""
        ì›ë˜ ì§ˆë¬¸: {original_question}

        ê²€ì¦ëœ ë°ì´í„°:
        {verified_data.get('validation_analysis', '')}

        ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ Perplexity ìŠ¤íƒ€ì¼ì˜ ì „ë¬¸ì ì¸ ë¦¬ì„œì¹˜ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

        # {original_question}

        ## ğŸ” í•µì‹¬ ìš”ì•½
        - 3-4ì¤„ë¡œ í•µì‹¬ ë‚´ìš© ìš”ì•½
        - ê°€ì¥ ì¤‘ìš”í•œ ë°œê²¬ì‚¬í•­

        ## ğŸ“Š ì£¼ìš” ë°œê²¬ì‚¬í•­
        1. **ì²« ë²ˆì§¸ í•µì‹¬ ë°œê²¬**
           - êµ¬ì²´ì ì¸ ë°ì´í„°ë‚˜ ì‚¬ì‹¤
           - ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜ ì •ë³´

        2. **ë‘ ë²ˆì§¸ í•µì‹¬ ë°œê²¬**
           - êµ¬ì²´ì ì¸ ë°ì´í„°ë‚˜ ì‚¬ì‹¤
           - ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜ ì •ë³´

        3. **ì„¸ ë²ˆì§¸ í•µì‹¬ ë°œê²¬**
           - êµ¬ì²´ì ì¸ ë°ì´í„°ë‚˜ ì‚¬ì‹¤
           - ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜ ì •ë³´

        ## ğŸ§­ ì‹¬ì¸µ ë¶„ì„
        - ë°ì´í„° ê°„ ì—°ê´€ì„± ë¶„ì„
        - íŒ¨í„´ê³¼ íŠ¸ë Œë“œ ì‹ë³„
        - ì „ë¬¸ê°€ ê´€ì  ì¢…í•©

        ## ğŸ”® ì‹œì‚¬ì  ë° ì „ë§
        - í˜„ì¬ ìƒí™©ì˜ ì˜ë¯¸
        - ë¯¸ë˜ ì „ë§
        - ì£¼ì˜í•  ì 

        ## âš ï¸ ì œí•œì‚¬í•­
        - ì •ë³´ì˜ í•œê³„ì 
        - ì¶”ê°€ ì¡°ì‚¬ í•„ìš” ì˜ì—­
        - ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„

        ## ğŸ“š ì°¸ê³  ì •ë³´
        - ì£¼ìš” ì¶œì²˜ë“¤
        - ê´€ë ¨ ë¦¬ì†ŒìŠ¤

        ---
        *ì´ ë³´ê³ ì„œëŠ” ì‹¤ì‹œê°„ ì›¹ê²€ìƒ‰ì„ í†µí•´ ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*

        ì „ë¬¸ì ì´ê³  ê°ê´€ì ì¸ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
        """

        if streaming_callback:
            streaming_callback("ğŸ“ ì¢…í•© ë³´ê³ ì„œ ì‘ì„± ì¤‘...\n")

        final_report = await agent._generate_basic_response(report_prompt, streaming_callback)
        
        return final_report

    async def _fallback_research(
        self, agent: Any, message: str, streaming_callback: Optional[Callable[[str], None]] = None
    ) -> str:
        """
        MCP ë„êµ¬ ì—†ì„ ë•Œ ê¸°ë³¸ ë¦¬ì„œì¹˜
        
        ì›¹ê²€ìƒ‰ ë„êµ¬ê°€ ì—†ëŠ” ê²½ìš° ê¸°ì¡´ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ
        ê¸°ë³¸ì ì¸ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.
        
        Args:
            agent: LLM ì—ì´ì „íŠ¸
            message: ë¦¬ì„œì¹˜ ì£¼ì œ
            streaming_callback: ì§„í–‰ ìƒí™© ì½œë°±
            
        Returns:
            str: ê¸°ë³¸ ì§€ì‹ ê¸°ë°˜ ë¶„ì„ ê²°ê³¼
        """
        if streaming_callback:
            streaming_callback("âš ï¸ ì›¹ê²€ìƒ‰ ë„êµ¬ê°€ ì—†ì–´ ê¸°ë³¸ ì§€ì‹ ê¸°ë°˜ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.\n\n")

        fallback_prompt = f"""
        ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ ê¸°ì¡´ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

        ì£¼ì œ: {message}

        ë‹¤ìŒ êµ¬ì¡°ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:
        1. ê¸°ë³¸ ê°œë… ì„¤ëª…
        2. ì£¼ìš” íŠ¹ì§• ë° í˜„í™©
        3. ê´€ë ¨ ë™í–¥ (ì¼ë°˜ì ì¸)
        4. ê³ ë ¤ì‚¬í•­
        5. ì¶”ì²œ ë¦¬ì†ŒìŠ¤ (ê²€ìƒ‰ í‚¤ì›Œë“œ)

        ì‹¤ì‹œê°„ ì›¹ê²€ìƒ‰ì€ ë¶ˆê°€í•˜ì§€ë§Œ ìµœëŒ€í•œ ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”.
        """

        return await agent._generate_basic_response(fallback_prompt, streaming_callback)

    def _format_search_data(self, data: Dict[str, str]) -> str:
        """
        ê²€ìƒ‰ ë°ì´í„° í¬ë§·íŒ…
        
        ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„°ë¥¼ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
        
        Args:
            data: ê²€ìƒ‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            
        Returns:
            str: í¬ë§·íŒ…ëœ ê²€ìƒ‰ ë°ì´í„°
        """
        formatted = []
        for key, content in data.items():
            # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ 500ìë¡œ ì œí•œ
            truncated_content = content[:500] + "..." if len(content) > 500 else content
            formatted.append(f"**{key}:**\n{truncated_content}\n")
        return "\n".join(formatted)

    def _extract_verified_facts(self, validation_text: str) -> List[str]:
        """
        ê²€ì¦ëœ ì‚¬ì‹¤ë“¤ ì¶”ì¶œ
        
        ê²€ì¦ ë¶„ì„ í…ìŠ¤íŠ¸ì—ì„œ í™•ì¸ëœ ì‚¬ì‹¤ë“¤ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            validation_text: ê²€ì¦ ë¶„ì„ ê²°ê³¼ í…ìŠ¤íŠ¸
            
        Returns:
            List[str]: ì¶”ì¶œëœ ê²€ì¦ ì‚¬ì‹¤ ëª©ë¡
        """
        facts = []
        lines = validation_text.split('\n')
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ê²€ì¦ëœ ì‚¬ì‹¤ ì¶”ì¶œ
        fact_keywords = ['í™•ì¸ë¨', 'ê²€ì¦ë¨', 'ì‚¬ì‹¤', 'ì‹ ë¢°', 'ì…ì¦', 'ì¦ëª…']
        
        for line in lines:
            line = line.strip()
            if line and any(keyword in line.lower() for keyword in fact_keywords):
                # ë¶ˆí•„ìš”í•œ ë§ˆí¬ë‹¤ìš´ ë¬¸ë²• ì œê±°
                cleaned_line = line.replace('*', '').replace('#', '').strip()
                if len(cleaned_line) > 10:  # ë„ˆë¬´ ì§§ì€ ë‚´ìš© ì œì™¸
                    facts.append(cleaned_line)
        
        return facts[:5]  # ìµœëŒ€ 5ê°œê¹Œì§€ë§Œ ë°˜í™˜ 