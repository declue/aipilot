"""
Perplexity ìŠ¤íƒ€ì¼ ì „ë¬¸ ë¦¬ì„œì¹˜ ì›Œí¬í”Œë¡œìš°
ì‹¤ì‹œê°„ ì›¹ê²€ìƒ‰ì„ í†µí•œ ì‹¬ì¸µì ì´ê³  ì „ë¬¸ì ì¸ ì¡°ì‚¬ ë° ë¶„ì„
"""

import logging
from typing import Any, Callable, Dict, List, Optional

from dspilot_core.llm.workflow.base_workflow import BaseWorkflow
from dspilot_core.util.logger import setup_logger

logger = setup_logger(__name__) or logging.getLogger(__name__)


class ResearchWorkflow(BaseWorkflow):
    """Perplexity ìŠ¤íƒ€ì¼ ì „ë¬¸ ë¦¬ì„œì¹˜ ì›Œí¬í”Œë¡œìš°"""

    def __init__(self):
        self.search_queries = []
        self.collected_sources = []
        self.research_depth = "comprehensive"  # basic, standard, comprehensive

    async def run(
        self, agent: Any, message: str, streaming_callback: Optional[Callable[[str], None]] = None
    ) -> str:
        """
        ì „ë¬¸ ë¦¬ì„œì¹˜ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰

        Args:
            agent: LLM ì—ì´ì „íŠ¸ (MCP ë„êµ¬ í•„ìš”)
            message: ë¦¬ì„œì¹˜ ì§ˆë¬¸/ì£¼ì œ
            streaming_callback: ìŠ¤íŠ¸ë¦¬ë° ì½œë°±

        Returns:
            str: ì¢…í•© ë¦¬ì„œì¹˜ ë³´ê³ ì„œ
        """
        try:
            logger.info(f"ì „ë¬¸ ë¦¬ì„œì¹˜ ì›Œí¬í”Œë¡œìš° ì‹œì‘: {message[:50]}...")

            # MCP ë„êµ¬ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸
            if not hasattr(agent, "mcp_tool_manager") or not agent.mcp_tool_manager:
                return await self._fallback_research(agent, message, streaming_callback)

            if streaming_callback:
                streaming_callback("ğŸ” **ì „ë¬¸ ë¦¬ì„œì¹˜ ì‹œì‘**\n\n")

            # 1ë‹¨ê³„: ë‹¤ê°ë„ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
            search_queries = await self._generate_search_queries(agent, message, streaming_callback)
            
            # 2ë‹¨ê³„: ì›¹ê²€ìƒ‰ ì‹¤í–‰ ë° ì •ë³´ ìˆ˜ì§‘
            raw_data = await self._execute_web_searches(agent, search_queries, streaming_callback)
            
            # 3ë‹¨ê³„: ì¶”ê°€ ì‹¬í™” ê²€ìƒ‰ (í•„ìš”ì‹œ)
            enhanced_data = await self._deep_dive_search(agent, message, raw_data, streaming_callback)
            
            # 4ë‹¨ê³„: ì •ë³´ ê²€ì¦ ë° ì‹ ë¢°ì„± í‰ê°€
            verified_data = await self._verify_and_validate(agent, enhanced_data, streaming_callback)
            
            # 5ë‹¨ê³„: ì¢…í•© ë¶„ì„ ë° ë³´ê³ ì„œ ìƒì„±
            final_report = await self._generate_comprehensive_report(
                agent, message, verified_data, streaming_callback
            )

            logger.info("ì „ë¬¸ ë¦¬ì„œì¹˜ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ")
            return final_report

        except Exception as e:
            logger.error(f"ì „ë¬¸ ë¦¬ì„œì¹˜ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return f"ë¦¬ì„œì¹˜ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    async def _generate_search_queries(
        self, agent: Any, topic: str, streaming_callback: Optional[Callable[[str], None]] = None
    ) -> List[str]:
        """ë‹¤ê°ë„ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±"""
        query_prompt = f"""
        ë‹¤ìŒ ì£¼ì œì— ëŒ€í•œ ì „ë¬¸ì ì´ê³  í¬ê´„ì ì¸ ë¦¬ì„œì¹˜ë¥¼ ìœ„í•œ ê²€ìƒ‰ ì¿¼ë¦¬ë“¤ì„ ìƒì„±í•´ì£¼ì„¸ìš”:

        ì£¼ì œ: {topic}

        ë‹¤ìŒ ê´€ì ì—ì„œ 5-7ê°œì˜ ë‹¤ì–‘í•œ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”:
        1. ê¸°ë³¸ ê°œë… ë° ì •ì˜
        2. ìµœì‹  ë™í–¥ ë° ë‰´ìŠ¤
        3. ì „ë¬¸ê°€ ì˜ê²¬ ë° ë¶„ì„
        4. í†µê³„ ë° ë°ì´í„°
        5. ê´€ë ¨ ì¼€ì´ìŠ¤ ìŠ¤í„°ë””
        6. ë¹„êµ ë¶„ì„ (ê²½ìŸì‚¬, ëŒ€ì•ˆ ë“±)
        7. ë¯¸ë˜ ì „ë§ ë° ì˜ˆì¸¡

        ê° ì¿¼ë¦¬ëŠ”:
        - êµ¬ì²´ì ì´ê³  ê²€ìƒ‰ ìµœì í™”ëœ í‚¤ì›Œë“œ ì‚¬ìš©
        - ì¤‘ë³µ ì—†ì´ ì„œë¡œ ë‹¤ë¥¸ ê´€ì  í¬í•¨
        - ì˜ì–´ì™€ í•œêµ­ì–´ í˜¼ìš© ê°€ëŠ¥

        JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
        {
            "queries": [
                "ê²€ìƒ‰ì¿¼ë¦¬1",
                "ê²€ìƒ‰ì¿¼ë¦¬2",
                ...
            ]
        }
        """

        if streaming_callback:
            streaming_callback("ğŸ“ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì¤‘...\n\n")

        response = await agent._generate_basic_response(query_prompt, None)
        
        # JSON íŒŒì‹±
        try:
            import json
            start_idx = response.find("{")
            end_idx = response.rfind("}") + 1
            if start_idx != -1 and end_idx != 0:
                json_str = response[start_idx:end_idx]
                query_data = json.loads(json_str)
                queries = query_data.get("queries", [])
            else:
                queries = [topic, f"{topic} latest news", f"{topic} analysis"]
        except Exception as e:
            logger.warning(f"ê²€ìƒ‰ ì¿¼ë¦¬ íŒŒì‹± ì‹¤íŒ¨: {e}")
            queries = [topic, f"{topic} ìµœì‹  ë™í–¥", f"{topic} ë¶„ì„", f"{topic} ì „ë¬¸ê°€ ì˜ê²¬"]

        self.search_queries = queries
        logger.debug(f"ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì™„ë£Œ: {len(queries)}ê°œ")
        return queries

    async def _execute_web_searches(
        self, agent: Any, queries: List[str], streaming_callback: Optional[Callable[[str], None]] = None
    ) -> Dict[str, str]:
        """ì›¹ê²€ìƒ‰ ì‹¤í–‰ ë° ì •ë³´ ìˆ˜ì§‘"""
        search_results = {}
        
        for i, query in enumerate(queries, 1):
            if streaming_callback:
                streaming_callback(f"ğŸŒ ê²€ìƒ‰ {i}/{len(queries)}: {query[:50]}...\n")

            try:
                # MCP ì›¹ê²€ìƒ‰ ë„êµ¬ ì‚¬ìš©
                search_prompt = f"ì›¹ì—ì„œ ë‹¤ìŒì— ëŒ€í•´ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•´ì£¼ì„¸ìš”: {query}"
                
                if hasattr(agent, "generate_response"):
                    result = await agent.generate_response(search_prompt, None)
                    search_content = result.get("response", "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                else:
                    search_content = await agent._generate_basic_response(search_prompt, None)
                
                search_results[f"query_{i}_{query[:30]}"] = search_content
                
            except Exception as e:
                logger.warning(f"ê²€ìƒ‰ ì‹¤íŒ¨ - {query}: {e}")
                search_results[f"query_{i}_{query[:30]}"] = f"ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}"

        if streaming_callback:
            streaming_callback(f"âœ… ì´ {len(search_results)}ê°œ ê²€ìƒ‰ ì™„ë£Œ\n\n")

        return search_results

    async def _deep_dive_search(
        self, agent: Any, original_topic: str, initial_data: Dict[str, str], 
        streaming_callback: Optional[Callable[[str], None]] = None
    ) -> Dict[str, str]:
        """ì‹¬í™” ê²€ìƒ‰ ì‹¤í–‰"""
        analysis_prompt = f"""
        ì›ë˜ ì£¼ì œ: {original_topic}
        
        ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ë“¤ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ ì‹ë³„í•´ì£¼ì„¸ìš”:
        {self._format_search_data(initial_data)}

        ë‹¤ìŒ ì¤‘ ì¶”ê°€ ì¡°ì‚¬ê°€ í•„ìš”í•œ ì˜ì—­ì´ ìˆë‹¤ë©´ 2-3ê°œì˜ ì¶”ê°€ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”:
        1. ë°ì´í„° ë¶€ì¡± ì˜ì—­
        2. ìƒì¶©ë˜ëŠ” ì •ë³´ê°€ ìˆëŠ” ë¶€ë¶„
        3. ë” ê¹Šì´ íŒŒì•¼ í•  ì „ë¬¸ ë¶„ì•¼
        4. ìµœì‹  ì—…ë°ì´íŠ¸ê°€ í•„ìš”í•œ ë¶€ë¶„

        JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
        {
            "need_additional_search": true/false,
            "additional_queries": ["ì¿¼ë¦¬1", "ì¿¼ë¦¬2", "ì¿¼ë¦¬3"],
            "reason": "ì¶”ê°€ ê²€ìƒ‰ì´ í•„ìš”í•œ ì´ìœ "
        }
        """

        if streaming_callback:
            streaming_callback("ğŸ”¬ ì‹¬í™” ë¶„ì„ ì¤‘...\n")

        response = await agent._generate_basic_response(analysis_prompt, None)
        
        try:
            import json
            start_idx = response.find("{")
            end_idx = response.rfind("}") + 1
            if start_idx != -1 and end_idx != 0:
                json_str = response[start_idx:end_idx]
                analysis = json.loads(json_str)
                
                if analysis.get("need_additional_search", False):
                    additional_queries = analysis.get("additional_queries", [])
                    if streaming_callback:
                        streaming_callback(f"ğŸ¯ ì¶”ê°€ ì‹¬í™” ê²€ìƒ‰ ì‹¤í–‰: {len(additional_queries)}ê°œ\n")
                    
                    additional_results = await self._execute_web_searches(
                        agent, additional_queries, streaming_callback
                    )
                    
                    # ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•©
                    enhanced_data = {**initial_data, **additional_results}
                    return enhanced_data
                    
        except Exception as e:
            logger.warning(f"ì‹¬í™” ê²€ìƒ‰ ë¶„ì„ ì‹¤íŒ¨: {e}")

        return initial_data

    async def _verify_and_validate(
        self, agent: Any, data: Dict[str, str], streaming_callback: Optional[Callable[[str], None]] = None
    ) -> Dict[str, Any]:
        """ì •ë³´ ê²€ì¦ ë° ì‹ ë¢°ì„± í‰ê°€"""
        validation_prompt = f"""
        ë‹¤ìŒ ê²€ìƒ‰ ê²°ê³¼ë“¤ì˜ ì‹ ë¢°ì„±ì„ í‰ê°€í•˜ê³  ê²€ì¦í•´ì£¼ì„¸ìš”:

        {self._format_search_data(data)}

        ê° ì •ë³´ì— ëŒ€í•´ ë‹¤ìŒì„ í‰ê°€í•´ì£¼ì„¸ìš”:
        1. ì •ë³´ì˜ ì‹ ë¢°ì„± (1-10ì )
        2. ì •ë³´ì˜ ìµœì‹ ì„± (1-10ì ) 
        3. ì¶œì²˜ì˜ ê¶Œìœ„ì„± (1-10ì )
        4. ì •ë³´ ê°„ ì¼ê´€ì„± í™•ì¸
        5. ì‚¬ì‹¤ í™•ì¸ì´ í•„ìš”í•œ ì£¼ì¥ë“¤

        ë˜í•œ ë‹¤ìŒì„ ì‹ë³„í•´ì£¼ì„¸ìš”:
        - ê°€ì¥ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ë“¤
        - ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•œ ì •ë³´ë“¤
        - ìƒì¶©ë˜ëŠ” ì •ë³´ê°€ ìˆëŠ” ê²½ìš° í•´ë‹¹ ë‚´ìš©

        ê²€ì¦ëœ í•µì‹¬ ì‚¬ì‹¤ë“¤ê³¼ ì£¼ì˜ì‚¬í•­ì„ ì •ë¦¬í•´ì£¼ì„¸ìš”.
        """

        if streaming_callback:
            streaming_callback("ğŸ” ì •ë³´ ê²€ì¦ ë° ì‹ ë¢°ì„± í‰ê°€ ì¤‘...\n")

        validation_result = await agent._generate_basic_response(validation_prompt, None)
        
        return {
            "raw_data": data,
            "validation_analysis": validation_result,
            "verified_facts": self._extract_verified_facts(validation_result)
        }

    async def _generate_comprehensive_report(
        self, agent: Any, original_question: str, verified_data: Dict[str, Any], 
        streaming_callback: Optional[Callable[[str], None]] = None
    ) -> str:
        """ì¢…í•© ë¦¬ì„œì¹˜ ë³´ê³ ì„œ ìƒì„±"""
        report_prompt = f"""
        ì›ë˜ ì§ˆë¬¸: {original_question}

        ê²€ì¦ëœ ë°ì´í„°:
        {verified_data.get('validation_analysis', '')}

        ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ Perplexity ìŠ¤íƒ€ì¼ì˜ ì „ë¬¸ì ì¸ ë¦¬ì„œì¹˜ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

        # {original_question}

        ## ğŸ” í•µì‹¬ ìš”ì•½
        - 3-4ì¤„ë¡œ í•µì‹¬ ë‚´ìš© ìš”ì•½
        - ê°€ì¥ ì¤‘ìš”í•œ ë°œê²¬ì‚¬í•­

        ## ğŸ“Š ì£¼ìš” ë°œê²¬ì‚¬í•­
        1. **ì²« ë²ˆì§¸ í•µì‹¬ ë°œê²¬**
           - êµ¬ì²´ì ì¸ ë°ì´í„°ë‚˜ ì‚¬ì‹¤
           - ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜ ì •ë³´

        2. **ë‘ ë²ˆì§¸ í•µì‹¬ ë°œê²¬**
           - êµ¬ì²´ì ì¸ ë°ì´í„°ë‚˜ ì‚¬ì‹¤
           - ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜ ì •ë³´

        3. **ì„¸ ë²ˆì§¸ í•µì‹¬ ë°œê²¬**
           - êµ¬ì²´ì ì¸ ë°ì´í„°ë‚˜ ì‚¬ì‹¤
           - ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜ ì •ë³´

        ## ğŸ§­ ì‹¬ì¸µ ë¶„ì„
        - ë°ì´í„° ê°„ ì—°ê´€ì„± ë¶„ì„
        - íŒ¨í„´ê³¼ íŠ¸ë Œë“œ ì‹ë³„
        - ì „ë¬¸ê°€ ê´€ì  ì¢…í•©

        ## ğŸ”® ì‹œì‚¬ì  ë° ì „ë§
        - í˜„ì¬ ìƒí™©ì˜ ì˜ë¯¸
        - ë¯¸ë˜ ì „ë§
        - ì£¼ì˜í•  ì 

        ## âš ï¸ ì œí•œì‚¬í•­
        - ì •ë³´ì˜ í•œê³„ì 
        - ì¶”ê°€ ì¡°ì‚¬ í•„ìš” ì˜ì—­
        - ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„

        ## ğŸ“š ì°¸ê³  ì •ë³´
        - ì£¼ìš” ì¶œì²˜ë“¤
        - ê´€ë ¨ ë¦¬ì†ŒìŠ¤

        ---
        *ì´ ë³´ê³ ì„œëŠ” ì‹¤ì‹œê°„ ì›¹ê²€ìƒ‰ì„ í†µí•´ ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*

        ì „ë¬¸ì ì´ê³  ê°ê´€ì ì¸ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
        """

        if streaming_callback:
            streaming_callback("ğŸ“ ì¢…í•© ë³´ê³ ì„œ ì‘ì„± ì¤‘...\n")

        final_report = await agent._generate_basic_response(report_prompt, streaming_callback)
        
        return final_report

    async def _fallback_research(
        self, agent: Any, message: str, streaming_callback: Optional[Callable[[str], None]] = None
    ) -> str:
        """MCP ë„êµ¬ ì—†ì„ ë•Œ ê¸°ë³¸ ë¦¬ì„œì¹˜"""
        if streaming_callback:
            streaming_callback("âš ï¸ ì›¹ê²€ìƒ‰ ë„êµ¬ê°€ ì—†ì–´ ê¸°ë³¸ ì§€ì‹ ê¸°ë°˜ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.\n\n")

        fallback_prompt = f"""
        ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ ê¸°ì¡´ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

        ì£¼ì œ: {message}

        ë‹¤ìŒ êµ¬ì¡°ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:
        1. ê¸°ë³¸ ê°œë… ì„¤ëª…
        2. ì£¼ìš” íŠ¹ì§• ë° í˜„í™©
        3. ê´€ë ¨ ë™í–¥ (ì¼ë°˜ì ì¸)
        4. ê³ ë ¤ì‚¬í•­
        5. ì¶”ì²œ ë¦¬ì†ŒìŠ¤ (ê²€ìƒ‰ í‚¤ì›Œë“œ)

        ì‹¤ì‹œê°„ ì›¹ê²€ìƒ‰ì€ ë¶ˆê°€í•˜ì§€ë§Œ ìµœëŒ€í•œ ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”.
        """

        return await agent._generate_basic_response(fallback_prompt, streaming_callback)

    def _format_search_data(self, data: Dict[str, str]) -> str:
        """ê²€ìƒ‰ ë°ì´í„° í¬ë§·íŒ…"""
        formatted = []
        for key, content in data.items():
            formatted.append(f"**{key}:**\n{content[:500]}...\n")
        return "\n".join(formatted)

    def _extract_verified_facts(self, validation_text: str) -> List[str]:
        """ê²€ì¦ëœ ì‚¬ì‹¤ë“¤ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì¶œ
        facts = []
        lines = validation_text.split('\n')
        for line in lines:
            if any(keyword in line.lower() for keyword in ['í™•ì¸ë¨', 'ê²€ì¦ë¨', 'ì‚¬ì‹¤', 'ì‹ ë¢°']):
                facts.append(line.strip())
        return facts[:5]  # ìµœëŒ€ 5ê°œ 