#!/usr/bin/env python3
"""
DSPilot CLI ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬ ëª¨ë“ˆ
=================================

ë³¸ ëª¨ë“ˆì€ CLI ì„¸ì…˜ ë™ì•ˆ ë°œìƒí•˜ëŠ” **ëŒ€í™” ë©”ì‹œì§€**ì™€ **ë³´ë¥˜ ì¤‘ ì‘ì—…(pending actions)**ì„
ê´€ë¦¬í•´ LLM í”„ë¡¬í”„íŠ¸ì— í•„ìš”í•œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

ê¸°ëŠ¥ ìš”ì•½
---------
1. History ê´€ë¦¬
   â€¢ add_to_history()  : ë©”ì‹œì§€ì™€ ë©”íƒ€ë°ì´í„° ì €ì¥
   â€¢ get_recent_context(): ìµœê·¼ Ní„´ë§Œ ì••ì¶•í•˜ì—¬ ë¬¸ìì—´ ì»¨í…ìŠ¤íŠ¸ ë°˜í™˜
2. Prompt ë¹Œë”
   â€¢ build_enhanced_prompt(): ëŒ€í™” ë§¥ë½ + ë³´ë¥˜ ì‘ì—… + ì‚¬ìš©ì ì…ë ¥ì„ ê²°í•©
3. Action ì¶”ì¶œ
   â€¢ extract_pending_actions(): LLM ì‘ë‹µì„ ìŠ¤ìº”í•˜ì—¬ íŒŒì¼ ìˆ˜ì • ì œì•ˆ ë“±ì„ ë³´ë¥˜ ëª©ë¡ì— ì¶”ê°€

ì•„í‚¤í…ì²˜
--------
```mermaid
flowchart LR
    A[ConversationManager] --> B((History))
    A --> C((Pending Actions))
    subgraph Prompt Builder
        B --> D[Recent Context]
        C --> D
    end
```

ì‹œí€€ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨ (í”„ë¡¬í”„íŠ¸ ìƒì„±)
--------------------------------
```mermaid
sequenceDiagram
    participant User
    participant CM as ConversationManager
    participant Agent
    User->>CM: add_to_history(role="user")
    CM-->>Agent: build_enhanced_prompt()
    Agent-->>CM: response
    CM->>CM: extract_pending_actions()
```

ì‚¬ìš© ì˜ˆì‹œ
---------
```python
cm = ConversationManager(max_context_turns=6)
cm.add_to_history("user", "ì•ˆë…•?")
cm.add_to_history("assistant", "ë°˜ê°€ì›Œ!")
print(cm.build_enhanced_prompt("ì˜¤ëŠ˜ ë‚ ì”¨ ì•Œë ¤ì¤˜"))
```

í…ŒìŠ¤íŠ¸ ì „ëµ
-----------
- `pytest.mark.parametrize` ë¡œ ë‹¤ì–‘í•œ history ê¸¸ì´ë¥¼ ê²€ì¦
- `freezegun.freeze_time` ìœ¼ë¡œ timestamp ì¼ê´€ì„± í™•ë³´
- `extract_pending_actions()` ëŠ” mock ì‘ë‹µì„ ì£¼ì…í•´ í‚¤ì›Œë“œÂ·í™•ì¥ì íƒì§€ ë¡œì§ì„ í…ŒìŠ¤íŠ¸
"""

from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

import dspilot_core.instructions.prompt_manager as prompt_manager
from dspilot_cli.constants import ConversationEntry, Defaults, PromptNames

# type: ignore  # pylint: disable=import-error
from dspilot_cli.summary_utils import compress_text

# ---------------------------------------------------------------------------
# í† í° ì¹´ìš´í„° ì´ˆê¸°í™” (tiktoken ìš°ì„ , ì—†ìœ¼ë©´ whitespace ê¸°ë°˜ fallback)
# ---------------------------------------------------------------------------
try:
    import tiktoken

    _DEFAULT_ENCODING = "cl100k_base"  # gpt-3.5/4 í˜¸í™˜
    _ENCODER = tiktoken.get_encoding(_DEFAULT_ENCODING)

    def _count_tokens(text: str) -> int:  # pylint: disable=missing-docstring
        return len(_ENCODER.encode(text))

except ModuleNotFoundError:  # pragma: no cover â€“ CIì— tiktokenì´ ì—†ì„ ë•Œ ëŒ€ë¹„

    def _count_tokens(text: str) -> int:  # type: ignore
        """í† í¬ë‚˜ì´ì €ê°€ ì—†ì„ ê²½ìš° ê³µë°± ë‹¨ìœ„ë¡œ ê·¼ì‚¬ ê³„ì‚°"""

        return len(text.split())


class ConversationManager:
    """ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬ë¥¼ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤

    SOLID ì›ì¹™ ì ìš©:
    - Single Responsibility: ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬ë§Œ ë‹´ë‹¹
    - Open/Closed: ìƒˆë¡œìš´ ëŒ€í™” ê´€ë¦¬ ì „ëµ ì¶”ê°€ ì‹œ ê¸°ì¡´ ì½”ë“œ ìˆ˜ì • ì—†ì´ í™•ì¥ ê°€ëŠ¥
    - Dependency Inversion: í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ìì— ì˜ì¡´í•˜ì—¬ í…œí”Œë¦¿ì„ ë™ì ìœ¼ë¡œ ë¡œë“œ
    """

    def __init__(self, max_context_turns: int = Defaults.MAX_CONTEXT_TURNS) -> None:
        """
        ëŒ€í™” ê´€ë¦¬ì ì´ˆê¸°í™”

        Args:
            max_context_turns: ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•  ìµœëŒ€ ëŒ€í™” í„´ ìˆ˜
        """
        self.conversation_history: List[ConversationEntry] = []
        self.pending_actions: List[str] = []
        self.max_context_turns = max_context_turns

        # í† í° ì˜ˆì‚° (ì „ì²´ í”„ë¡¬í”„íŠ¸ ê¸°ì¤€). ì‹œìŠ¤í…œ/ì§€ì‹œë¬¸ ì—¬ìœ ë¡œ 10% ë²„í¼ í™•ë³´
        self.max_prompt_tokens = Defaults.MAX_PROMPT_TOKENS
        self._context_token_budget = int(self.max_prompt_tokens * 0.9)

        # í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ì ì£¼ì… (ëª¨ë“ˆ ë°©ì‹ìœ¼ë¡œ ë¶ˆëŸ¬ì™€ í…ŒìŠ¤íŠ¸ ì¤‘ ëª¨í‚¹ ê°€ëŠ¥)
        self.prompt_manager = prompt_manager.get_default_prompt_manager()

    # ------------------------------------------------------------------
    # ë‚´ë¶€ ìœ í‹¸ í•¨ìˆ˜ë“¤
    # ------------------------------------------------------------------

    @staticmethod
    def _role_prefix(role: str) -> str:
        """ì—­í• ì— ë”°ë¥¸ í”„ë¦¬í”½ìŠ¤ ì´ëª¨í‹°ì½˜"""

        return "ğŸ‘¤ User" if role == "user" else "ğŸ¤– Assistant"

    def _format_entry(self, entry: ConversationEntry) -> str:
        """ConversationEntry ë¥¼ í”„ë¡¬í”„íŠ¸ìš© ë¬¸ìì—´ë¡œ ë³€í™˜"""

        role_prefix = self._role_prefix(entry.role)
        part = f"{role_prefix}: {entry.content}"

        if entry.metadata.get("used_tools"):
            tools = ", ".join(str(tool)
                              for tool in entry.metadata["used_tools"])
            part += f"\n   [ì‚¬ìš©ëœ ë„êµ¬: {tools}]"
        return part

    def _select_messages_within_budget(self, budget_tokens: int) -> Tuple[List[str], List[ConversationEntry]]:
        """í† í° ì˜ˆì‚° ë‚´ì—ì„œ ê°€ì¥ ìµœê·¼ ë©”ì‹œì§€ë“¤ì„ ì„ íƒ

        ë°˜í™˜ëœ ë¦¬ìŠ¤íŠ¸ëŠ” *ì‹œê°„ìˆœ(ê³¼ê±°â†’í˜„ì¬)* ì…ë‹ˆë‹¤.
        """

        selected_lines: List[str] = []
        selected_entries: List[ConversationEntry] = []

        current_tokens = 0

        # ìµœì‹  ë©”ì‹œì§€ë¶€í„° ê±°ê¾¸ë¡œ ì¶”ê°€ í›„, ìµœì¢…ì ìœ¼ë¡œ reverse í•˜ì—¬ ì‹œê°„ìˆœ ë§ì¶¤
        for entry in reversed(self.conversation_history):
            formatted = self._format_entry(entry)
            entry_tokens = _count_tokens(formatted)

            if current_tokens + entry_tokens > budget_tokens:
                break

            selected_lines.append(formatted)
            selected_entries.append(entry)
            current_tokens += entry_tokens

        selected_lines.reverse()
        selected_entries.reverse()
        return selected_lines, selected_entries

    def add_to_history(self,
                       role: str,
                       content: str,
                       metadata: Optional[Dict[str, Any]] = None) -> None:
        """
        ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ë©”ì‹œì§€ ì¶”ê°€

        Args:
            role: ì—­í•  (user, assistant)
            content: ë©”ì‹œì§€ ë‚´ìš©
            metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„°
        """
        entry = ConversationEntry(
            role=role,
            content=content,
            timestamp=datetime.now().isoformat(),
            metadata=metadata or {}
        )
        self.conversation_history.append(entry)

    def get_recent_context(self, max_turns: Optional[int] = None) -> str:
        """
        ìµœê·¼ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜

        Args:
            max_turns: ìµœëŒ€ í„´ ìˆ˜ (ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)

        Returns:
            ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´
        """
        if not self.conversation_history:
            return ""

        # 1) í† í° ì˜ˆì‚°ìœ¼ë¡œ ìš°ì„  í•„í„°ë§ -----------------------------------
        selected_lines, _ = self._select_messages_within_budget(
            self._context_token_budget)

        # 2) ì¶”ê°€ë¡œ í„´ ìˆ˜ ì œí•œ ì ìš© (ì˜ˆ: ìµœê·¼ 5í„´ ìœ ì§€). í† í°ë³´ë‹¤ ê°•í•œ ì œì•½ ì•„ë‹˜.
        turns = max_turns or self.max_context_turns
        if turns > 0:
            max_messages = turns * 2  # user+assistant í•œ í„´ = 2 ë©”ì‹œì§€
            if len(selected_lines) > max_messages:
                selected_lines = selected_lines[-max_messages:]

        return "\n".join(selected_lines)

    def build_enhanced_prompt(self, user_input: str) -> str:
        """
        ì´ì „ ëŒ€í™” ë§¥ë½ì„ í¬í•¨í•œ í–¥ìƒëœ í”„ë¡¬í”„íŠ¸ ìƒì„±

        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥

        Returns:
            í–¥ìƒëœ í”„ë¡¬í”„íŠ¸
        """
        context = self.get_recent_context()

        # ë³´ë¥˜ ì¤‘ì¸ ì‘ì—…ì´ ìˆìœ¼ë©´ í¬í•¨
        pending_context = ""
        if self.pending_actions:
            pending_context = "\n\n[ë³´ë¥˜ ì¤‘ì¸ ì‘ì—…ë“¤]:\n" + \
                              "\n".join(
                                  f"- {action}" for action in self.pending_actions)

        if not context:
            # ì»¨í…ìŠ¤íŠ¸ ì—†ìœ¼ë©´ ë‹¨ìˆœ í”„ë¡¬í”„íŠ¸
            return f"{pending_context}\n\n{user_input}" if pending_context else user_input

        # ENHANCED í”„ë¡¬í”„íŠ¸ êµ¬ì„± (íŒŒì¼ì—ì„œ ë¡œë“œ)
        try:
            enhanced_prompt = self.prompt_manager.get_formatted_prompt(
                PromptNames.ENHANCED,
                context=context,
                pending_context=pending_context,
                user_input=user_input
            )

            if enhanced_prompt is None:
                # í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í˜•íƒœ
                enhanced_prompt = f"ì´ì „ ëŒ€í™” ë§¥ë½:\n{context}\n\n{pending_context}\n\ní˜„ì¬ ì‚¬ìš©ì ìš”ì²­: {user_input}"

        except Exception:
            # í¬ë§·íŒ… ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í˜•íƒœ
            enhanced_prompt = f"ì´ì „ ëŒ€í™” ë§¥ë½:\n{context}\n\n{pending_context}\n\ní˜„ì¬ ì‚¬ìš©ì ìš”ì²­: {user_input}"

        # ------------------------------------------------------------------
        # ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ê°€ í† í° ì˜ˆì‚°ì„ ì´ˆê³¼í•˜ë©´ ìš”ì•½(compaction) ìˆ˜í–‰
        # ------------------------------------------------------------------
        total_tokens = _count_tokens(enhanced_prompt)
        if total_tokens > self.max_prompt_tokens:
            # ì´ˆê³¼ëŸ‰ë§Œí¼ ì˜¤ë˜ëœ ë©”ì‹œì§€ ì œê±° í›„ ì¬ìƒì„±
            # ê°„ë‹¨ ë²„ì „: ì»¨í…ìŠ¤íŠ¸ì—ì„œ ê°€ì¥ ì˜¤ë˜ëœ ë‘ ì¤„ ì œê±° ë°˜ë³µ
            context_lines = context.split("\n")
            while context_lines and total_tokens > self.max_prompt_tokens:
                # 1) ì˜¤ë˜ëœ ë©”ì‹œì§€ ì œê±° í›„ ì¬í‰ê°€
                context_lines = context_lines[2:]
                context = "\n".join(context_lines)

                enhanced_prompt = self.prompt_manager.get_formatted_prompt(
                    PromptNames.ENHANCED,
                    context=context,
                    pending_context=pending_context,
                    user_input=user_input
                ) or f"ì´ì „ ëŒ€í™” ë§¥ë½:\n{context}\n\n{pending_context}\n\ní˜„ì¬ ì‚¬ìš©ì ìš”ì²­: {user_input}"

                # Ensure enhanced_prompt is a string before counting tokens
                prompt_text = str(
                    enhanced_prompt) if enhanced_prompt is not None else ""
                total_tokens = _count_tokens(prompt_text)

            # 2) ê·¸ë˜ë„ ì´ˆê³¼í•˜ë©´ ìš”ì•½ ì••ì¶• ì‹œë„
            if total_tokens > self.max_prompt_tokens and context_lines:
                compressed_context = compress_text("\n".join(context_lines))
                enhanced_prompt = self.prompt_manager.get_formatted_prompt(
                    PromptNames.ENHANCED,
                    context=compressed_context,
                    pending_context=pending_context,
                    user_input=user_input
                ) or f"ì´ì „ ëŒ€í™” ë§¥ë½(ìš”ì•½):\n{compressed_context}\n\n{pending_context}\n\ní˜„ì¬ ì‚¬ìš©ì ìš”ì²­: {user_input}"

        return enhanced_prompt

    def extract_pending_actions(self, response_data: Dict[str, Any]) -> None:
        """
        ì‘ë‹µì—ì„œ ë³´ë¥˜ ì¤‘ì¸ ì‘ì—…ë“¤ì„ ì¶”ì¶œí•˜ì—¬ ì €ì¥

        Args:
            response_data: ì‘ë‹µ ë°ì´í„°
        """
        response = response_data.get("response", "")

        # ê°„ë‹¨í•œ íŒ¨í„´ìœ¼ë¡œ ì œì•ˆëœ ë³€ê²½ì‚¬í•­ ê°ì§€ (ë²”ìš©ì  ì ‘ê·¼)
        keywords = ["ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤", "ë³€ê²½í•˜ê² ìŠµë‹ˆë‹¤", "ì ìš©í•˜ê² ìŠµë‹ˆë‹¤", "ìˆ˜ì •í• ê¹Œìš”", "ë³€ê²½í• ê¹Œìš”"]
        if any(keyword in response.lower() for keyword in keywords):
            # ì½”ë“œ ë¸”ë¡ì´ë‚˜ íŒŒì¼ ê²½ë¡œê°€ í¬í•¨ëœ ê²½ìš°
            extensions = [".py", ".js", ".ts", ".java", ".cpp", ".txt"]
            if "```" in response or any(ext in response for ext in extensions):
                self.pending_actions.append("íŒŒì¼ ìˆ˜ì •/ìƒì„± ì‘ì—…")

        # ìµœëŒ€ Nê°œì˜ ë³´ë¥˜ ì‘ì—…ë§Œ ìœ ì§€
        if len(self.pending_actions) > Defaults.MAX_PENDING_ACTIONS:
            self.pending_actions = self.pending_actions[-Defaults.MAX_PENDING_ACTIONS:]

    def clear_pending_actions(self) -> None:
        """ë³´ë¥˜ ì¤‘ì¸ ì‘ì—…ë“¤ ì´ˆê¸°í™”"""
        self.pending_actions.clear()

    def clear_conversation(self) -> None:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"""
        self.conversation_history.clear()
        self.clear_pending_actions()

    def get_conversation_count(self) -> int:
        """ëŒ€í™” ë©”ì‹œì§€ ê°œìˆ˜ ë°˜í™˜"""
        return len(self.conversation_history)

    def get_pending_actions(self) -> List[str]:
        """ë³´ë¥˜ ì¤‘ì¸ ì‘ì—… ëª©ë¡ ë°˜í™˜"""
        return self.pending_actions.copy()

    def has_pending_actions(self) -> bool:
        """ë³´ë¥˜ ì¤‘ì¸ ì‘ì—…ì´ ìˆëŠ”ì§€ í™•ì¸"""
        return bool(self.pending_actions)
