#!/usr/bin/env python3
"""
DSPilot CLI ê³„íš ìˆ˜ë¦½ ì„œë¹„ìŠ¤ (PlanningService)
============================================

ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ **ExecutionPlan(JSON)** ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì»´í¬ë„ŒíŠ¸ì…ë‹ˆë‹¤.
LangChain í˜¸í™˜ MCP Tool ë©”íƒ€ë°ì´í„°ë¥¼ LLM ì— ì „ë‹¬í•˜ê³ , ì‘ë‹µì—ì„œ JSON ê³„íšì„
ì¶”ì¶œÂ·ê²€ì¦í•œ ë’¤ `ExecutionManager` ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

ì•Œê³ ë¦¬ì¦˜ ë‹¨ê³„
-------------
1. ì‚¬ìš© ê°€ëŠ¥í•œ MCP ë„êµ¬ ë©”íƒ€ì •ë³´ ìˆ˜ì§‘ (`_get_available_tools`)
2. ì›Œí¬í”Œë¡œìš° íŒ¨í„´ ê°ì§€ ë° ë¶„ê¸° (`_detect_workflow_pattern`)
3. ë¶„ì„ í”„ë¡¬í”„íŠ¸ ë Œë”ë§ ë° LLM í˜¸ì¶œ
4. LLM ì‘ë‹µì—ì„œ JSON êµ¬ì¡° ì¶”ì¶œ (`_parse_plan_response`)
5. `need_tools` í”Œë˜ê·¸ê°€ True ì´ë©´ `_create_execution_plan` ìˆ˜í–‰

ë°ì´í„° íë¦„
-----------
```mermaid
sequenceDiagram
    participant EM as ExecutionManager
    participant PS as PlanningService
    participant WF as Workflow
    participant AG as LLM Agent
    EM->>PS: analyze_request_and_plan(user_message)
    PS->>PS: _detect_workflow_pattern(user_message)
    alt íŠ¹ë³„í•œ ì›Œí¬í”Œë¡œìš° íŒ¨í„´ ê°ì§€
        PS->>WF: run(agent, message)
        WF-->>PS: ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ê²°ê³¼
        PS-->>EM: None (ì›Œí¬í”Œë¡œìš°ê°€ ì§ì ‘ ì²˜ë¦¬)
    else ì¼ë°˜ ë„êµ¬ ì‹¤í–‰ ê³„íš
        PS->>AG: analysis_prompt
        AG-->>PS: JSON (need_tools, plan)
        PS-->>EM: ExecutionPlan | None
    end
```

í™•ì¥ ê°€ì´ë“œ
-----------
- ìƒˆë¡œìš´ ì›Œí¬í”Œë¡œìš° íŒ¨í„´ì„ ì¶”ê°€í•˜ë ¤ë©´ `_detect_workflow_pattern` ë©”ì„œë“œë¥¼ í™•ì¥í•˜ì„¸ìš”.
- ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ ë²„ì „ì„ ì¶”ê°€í•˜ë ¤ë©´ `PromptNames` ì— ìƒìˆ˜ë¥¼ ì •ì˜í•˜ê³ , í”„ë¡¬í”„íŠ¸íŒŒì¼ì„ í…œí”Œë¦¿ ë””ë ‰í„°ë¦¬ì— ë„£ìœ¼ì„¸ìš”.
- JSON íŒŒì‹± ê·œì¹™ì´ ë³€ê²½ë˜ë©´ `_parse_plan_response` ë¥¼ ì˜¤ë²„ë¼ì´ë“œí•˜ì—¬ ë§ì¶¤ ì²˜ë¦¬ ê°€ëŠ¥í•©ë‹ˆë‹¤.

í…ŒìŠ¤íŠ¸ ì „ëµ
-----------
- ì‹¤íŒ¨ ì¼€ì´ìŠ¤: LLM ì´ ë¹„JSON ì‘ë‹µì„ ë°˜í™˜í•  ë•Œ None ì´ ë°˜í™˜ë˜ëŠ”ì§€ í™•ì¸
- ì„±ê³µ ì¼€ì´ìŠ¤: ë¯¸ë¦¬ ì¤€ë¹„ëœ ìƒ˜í”Œ JSON ì‘ë‹µì„ ì£¼ì…í•´ ExecutionPlan ê°ì²´ ìƒì„± ê²€ì¦
- ì›Œí¬í”Œë¡œìš° ë¶„ê¸°: íŠ¹ì • íŒ¨í„´ ê°ì§€ ì‹œ ì˜¬ë°”ë¥¸ ì›Œí¬í”Œë¡œìš°ê°€ í˜¸ì¶œë˜ëŠ”ì§€ í™•ì¸
"""

import json
import re
from typing import Any, Dict, List, Optional

import dspilot_core.instructions.prompt_manager as prompt_manager
from dspilot_cli.constants import ExecutionPlan, ExecutionStep, PromptNames
from dspilot_cli.output_manager import OutputManager
from dspilot_core.llm.agents.base_agent import BaseAgent
from dspilot_core.llm.mcp.mcp_tool_manager import MCPToolManager
from dspilot_core.llm.models.conversation_message import ConversationMessage
from dspilot_core.llm.workflow import get_workflow


class PlanningService:
    """ìš”ì²­ ë¶„ì„ ë° ì‹¤í–‰ ê³„íš ìˆ˜ë¦½ì„ ë‹´ë‹¹í•˜ëŠ” ì„œë¹„ìŠ¤"""

    def __init__(self, output_manager: OutputManager,
                 llm_agent: BaseAgent,
                 mcp_tool_manager: MCPToolManager) -> None:
        """
        ê³„íš ìˆ˜ë¦½ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”

        Args:
            output_manager: ì¶œë ¥ ê´€ë¦¬ì
            llm_agent: LLM ì—ì´ì „íŠ¸
            mcp_tool_manager: MCP ë„êµ¬ ê´€ë¦¬ì
        """
        self.output_manager = output_manager
        self.llm_agent = llm_agent
        self.mcp_tool_manager = mcp_tool_manager
        self.prompt_manager = prompt_manager.get_default_prompt_manager()

    async def analyze_request_and_plan(self, user_message: str) -> Optional[ExecutionPlan]:
        """
        ìš”ì²­ ë¶„ì„ ë° ì‹¤í–‰ ê³„íš ìˆ˜ë¦½

        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€

        Returns:
            ì‹¤í–‰ ê³„íš (ë„êµ¬ê°€ í•„ìš”í•˜ì§€ ì•Šê±°ë‚˜ ì›Œí¬í”Œë¡œìš°ë¡œ ì²˜ë¦¬ëœ ê²½ìš° None)
        """
        try:
            # 1. ì›Œí¬í”Œë¡œìš° íŒ¨í„´ ê°ì§€ ë° ë¶„ê¸°
            workflow_result = await self._detect_and_execute_workflow(user_message)
            if workflow_result is not None:
                # ì›Œí¬í”Œë¡œìš°ê°€ ì§ì ‘ ì²˜ë¦¬í•œ ê²½ìš°, ì‹¤í–‰ ê³„íš ë¶ˆí•„ìš”
                self.output_manager.log_if_debug("ì›Œí¬í”Œë¡œìš°ê°€ ìš”ì²­ì„ ì§ì ‘ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.")
                return None

            # 2. ì¼ë°˜ì ì¸ ë„êµ¬ ì‹¤í–‰ ê³„íš ìˆ˜ë¦½
            return await self._create_standard_execution_plan(user_message)

        except Exception as e:
            self.output_manager.log_if_debug(f"ê³„íš ìˆ˜ë¦½ ì‹¤íŒ¨: {e}", "warning")
            return None

    async def _detect_and_execute_workflow(self, user_message: str) -> Optional[str]:
        """
        ì›Œí¬í”Œë¡œìš° íŒ¨í„´ì„ ê°ì§€í•˜ê³  í•´ë‹¹ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€

        Returns:
            ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ê²°ê³¼ (íŒ¨í„´ì´ ê°ì§€ë˜ì§€ ì•Šìœ¼ë©´ None)
        """
        # ì½”ë“œ ìˆ˜ì • íŒ¨í„´ ê°ì§€
        # 1. ì½”ë“œ ìˆ˜ì • íŒ¨í„´ ê°ì§€ ë° ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        if await self._is_code_modification_request(user_message):
            self.output_manager.log_if_debug("ì½”ë“œ ìˆ˜ì • íŒ¨í„´ ê°ì§€, CodeModificationWorkflow ì‹¤í–‰")
            
            def streaming_callback(content: str) -> None:
                self.output_manager.log_if_debug(f"[ì›Œí¬í”Œë¡œìš°] {content.strip()}")

            try:
                workflow_class = get_workflow("code_mod")
                workflow = workflow_class()
                result = await workflow.run(self.llm_agent, user_message, streaming_callback)
                self.output_manager.log_if_debug(f"ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì™„ë£Œ: {result}")
                return result
            except Exception as e:
                self.output_manager.log_if_debug(f"ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹¤íŒ¨: {e}", "error")
                return None

        # 2. ë¦¬ì„œì¹˜/ê²€ìƒ‰ íŒ¨í„´ ê°ì§€ ë° ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        if await self._is_research_request(user_message):
            self.output_manager.log_if_debug("ë¦¬ì„œì¹˜ íŒ¨í„´ ê°ì§€, ResearchWorkflow ì‹¤í–‰")
            
            def research_streaming_callback(content: str) -> None:
                self.output_manager.log_if_debug(f"[ì›Œí¬í”Œë¡œìš°] {content.strip()}")

            try:
                workflow_class = get_workflow("research")
                workflow = workflow_class()
                result = await workflow.run(self.llm_agent, user_message, research_streaming_callback)
                self.output_manager.log_if_debug(f"ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì™„ë£Œ: {result}")
                return result
            except Exception as e:
                self.output_manager.log_if_debug(f"ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹¤íŒ¨: {e}", "error")
                return None

        return None

    async def _is_code_modification_request(self, user_message: str) -> bool:
        """
        ì½”ë“œ ìˆ˜ì • ìš”ì²­ì¸ì§€ íŒë‹¨í•©ë‹ˆë‹¤.

        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€

        Returns:
            ì½”ë“œ ìˆ˜ì • ìš”ì²­ ì—¬ë¶€
        """
        # ë©”íƒ€ë°ì´í„° ê¸°ë°˜ íŒ¨í„´ ê°ì§€
        code_modification_keywords = [
            "ìˆ˜ì •", "ë³€ê²½", "ê³ ì¹˜", "ë°”ê¾¸", "ê°œì„ ", "ë¦¬íŒ©í† ë§", "refactor", 
            "modify", "change", "update", "fix", "edit", "íŒŒì¼ ìˆ˜ì •", "ì½”ë“œ ìˆ˜ì •"
        ]
        
        file_extension_keywords = [
            ".py", ".js", ".ts", ".java", ".cpp", ".c", ".go", ".rs", ".rb", ".php"
        ]
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ 1ì°¨ í•„í„°ë§
        message_lower = user_message.lower()
        has_modification_keyword = any(keyword in message_lower for keyword in code_modification_keywords)
        has_file_reference = any(ext in message_lower for ext in file_extension_keywords)
        
        # íŒŒì¼ ê²½ë¡œ íŒ¨í„´ ê°ì§€ (ì˜ˆ: /path/to/file.py, ./src/main.js ë“±)
        import re
        file_path_pattern = r'[\w\-\.\/\\]+\.\w{2,4}'
        has_file_path = bool(re.search(file_path_pattern, user_message))
        
        return has_modification_keyword and (has_file_reference or has_file_path)

    async def _is_research_request(self, user_message: str) -> bool:
        """
        ë¦¬ì„œì¹˜/ê²€ìƒ‰ ìš”ì²­ì¸ì§€ íŒë‹¨í•©ë‹ˆë‹¤.
        
        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            
        Returns:
            ë¦¬ì„œì¹˜ ìš”ì²­ ì—¬ë¶€
        """
        # ë©”íƒ€ë°ì´í„° ê¸°ë°˜ íŒ¨í„´ ê°ì§€
        research_keywords = [
            "ê²€ìƒ‰", "ì°¾ì•„", "ì•Œì•„ë´", "ì¡°ì‚¬", "ë¦¬ì„œì¹˜", "research", "search",
            "ë‰´ìŠ¤", "ì •ë³´", "ë™í–¥", "íŠ¸ë Œë“œ", "í˜„í™©", "ë¶„ì„", "ìš”ì•½"
        ]
        
        # ì¢…í•©ì ì¸ ì‘ì—…ì„ ë‚˜íƒ€ë‚´ëŠ” í‚¤ì›Œë“œ
        comprehensive_keywords = [
            "ìš”ì•½í•´ì„œ", "ì •ë¦¬í•´ì„œ", "íŒŒì¼ë¡œ ì €ì¥", "ë¸”ë¡œê·¸", "ë³´ê³ ì„œ", 
            "ì •ë¦¬ëœ ë‚´ìš©", "ì¢…í•©", "ì·¨í•©"
        ]
        
        message_lower = user_message.lower()
        
        # 1ì°¨: ë¦¬ì„œì¹˜ ê´€ë ¨ í‚¤ì›Œë“œ ì¡´ì¬
        has_research_keyword = any(keyword in message_lower for keyword in research_keywords)
        
        # 2ì°¨: ì¢…í•©ì  ì‘ì—… í‚¤ì›Œë“œ ì¡´ì¬ (ê²€ìƒ‰ + ê°€ê³µ + ì €ì¥)
        has_comprehensive_keyword = any(keyword in message_lower for keyword in comprehensive_keywords)
        
        # 3ì°¨: ì‹œê°„ ë²”ìœ„ í‚¤ì›Œë“œ (ìµœì‹ ì„± ìš”êµ¬)
        time_keywords = ["ìµœì‹ ", "ì–´ì œ", "ì˜¤ëŠ˜", "ì´ë²ˆì£¼", "ìµœê·¼", "latest", "recent"]
        has_time_keyword = any(keyword in message_lower for keyword in time_keywords)
        
        # ë¦¬ì„œì¹˜ íŒ¨í„´ íŒë‹¨: (ê²€ìƒ‰ í‚¤ì›Œë“œ + ì¢…í•© ì‘ì—…) ë˜ëŠ” (ê²€ìƒ‰ í‚¤ì›Œë“œ + ì‹œê°„ í‚¤ì›Œë“œ)
        return has_research_keyword and (has_comprehensive_keyword or has_time_keyword)

    async def _create_standard_execution_plan(self, user_message: str) -> Optional[ExecutionPlan]:
        """
        í‘œì¤€ ì‹¤í–‰ ê³„íšì„ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€

        Returns:
            ì‹¤í–‰ ê³„íš (ë„êµ¬ê°€ í•„ìš”í•˜ì§€ ì•Šìœ¼ë©´ None)
        """
        # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ í™•ì¸
        available_tools = await self._get_available_tools()
        if not available_tools:
            return None

        # ë„êµ¬ ëª©ë¡ ìƒì„± (ì´ë¦„ + ì„¤ëª… + íŒŒë¼ë¯¸í„° ëª©ë¡ í¬í•¨)
        tool_lines = []
        for tool in available_tools:
            param_fields = getattr(tool, "args", None) or getattr(tool, "args_schema", None)
            param_names: List[str] = []
            if param_fields:
                try:
                    param_names = list(param_fields.__fields__.keys())  # type: ignore[attr-defined]
                except Exception:
                    param_names = list(param_fields.keys()) if isinstance(param_fields, dict) else []

            params_str = f"({', '.join(param_names)})" if param_names else ""
            tool_lines.append(f"- {tool.name}{params_str}: {tool.description}")

        tools_desc = "\n".join(tool_lines)

        # ê³„íš ìˆ˜ë¦½ í”„ë¡¬í”„íŠ¸ (íŒŒì¼ì—ì„œ ë¡œë“œ)
        analysis_prompt = self.prompt_manager.get_formatted_prompt(
            PromptNames.ANALYSIS,
            user_message=user_message,
            tools_desc=tools_desc
        )

        if analysis_prompt is None:
            self.output_manager.log_if_debug("ë¶„ì„ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨", "error")
            return None

        context = [ConversationMessage(
            role="user", content=analysis_prompt)]
        response = await self.llm_agent.llm_service.generate_response(context)

        # ë””ë²„ê·¸ ëª¨ë“œì—ì„œëŠ” LLM ì‘ë‹µ ì›ë¬¸ ì¼ë¶€ ë¡œê·¸
        self.output_manager.log_if_debug(
            f"[LLM-RAW-PLAN] {response.response[:500].replace('\n', ' ') if isinstance(response.response, str) else str(response)[:500]}"
        )

        # JSON íŒŒì‹±
        plan_data = self._parse_plan_response(response.response)
        if plan_data and plan_data.get("need_tools", False):
            # LLM ì´ ëª©ë¡ì— ì—†ëŠ” ë„êµ¬ë¥¼ ì°¸ì¡°í•˜ëŠ” ê²½ìš° í•„í„°ë§
            valid_tool_names = {tool.name for tool in available_tools}

            raw_plan = plan_data.get("plan", {})
            if not raw_plan or not raw_plan.get("steps"):
                return None
                
            filtered_steps = [
                s for s in raw_plan.get("steps", []) if s.get("tool_name") in valid_tool_names
            ]

            # ìŠ¤í…ì´ ëª¨ë‘ ì œê±°ë˜ë©´ ë„êµ¬ ì‹¤í–‰ ë¶ˆí•„ìš”
            if not filtered_steps:
                return None

            # ìµœì¢… ìŠ¤í… ë°°ì—´ ì¬ì •ë ¬ (step í‚¤ ê¸°ì¤€)
            filtered_steps.sort(key=lambda s: s.get("step", 0))
            
            # ê³„íš ê²€ì¦ ë° ìˆ˜ì •
            validated_steps = self._validate_and_fix_plan_steps(filtered_steps)
            raw_plan["steps"] = validated_steps

            execution_plan = self._create_execution_plan(raw_plan)
            # ì‹¤í–‰ ë‹¨ê³„ê°€ ì—†ëŠ” ê²½ìš°ëŠ” ë„êµ¬ ì‹¤í–‰ì´ ë¶ˆí•„ìš”í•œ ê²ƒê³¼ ë™ì¼í•˜ê²Œ ê°„ì£¼í•˜ì—¬ None ë°˜í™˜
            if execution_plan and execution_plan.steps:
                return execution_plan

        return None

    async def _get_available_tools(self) -> List[Any]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        available_tools = []
        if self.mcp_tool_manager and hasattr(self.mcp_tool_manager, 'get_langchain_tools'):
            try:
                available_tools = await self.mcp_tool_manager.get_langchain_tools()
            except Exception as e:
                self.output_manager.log_if_debug(
                    f"ë„êµ¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}", "warning")
        return available_tools

    def _parse_plan_response(self, response_text: str) -> Optional[Dict[str, Any]]:
        """ì‘ë‹µì—ì„œ JSON ê³„íš íŒŒì‹±"""
        try:
            start_idx = response_text.find("{")
            end_idx = response_text.rfind("}") + 1
            if start_idx != -1 and end_idx != 0:
                json_str = response_text[start_idx:end_idx]
                result: Dict[str, Any] = json.loads(json_str)
                return result
        except (json.JSONDecodeError, ValueError):
            pass
        return None

    def _create_execution_plan(self, plan_data: Dict[str, Any]) -> ExecutionPlan:
        """ê³„íš ë°ì´í„°ë¡œë¶€í„° ExecutionPlan ê°ì²´ ìƒì„±"""
        steps = []
        for step_data in plan_data.get("steps", []):
            step = ExecutionStep(
                step=step_data.get("step", 0),
                description=step_data.get("description", ""),
                tool_name=step_data.get("tool_name", ""),
                arguments=step_data.get("arguments", {}),
                confirm_message=step_data.get("confirm_message", "")
            )
            steps.append(step)

        return ExecutionPlan(
            description=plan_data.get("description", "ë„êµ¬ ì‹¤í–‰ ê³„íš"),
            steps=steps
        )

    def _validate_and_fix_plan_steps(self, steps: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ê³„íš ë‹¨ê³„ë“¤ì„ ê²€ì¦í•˜ê³  ì˜ëª»ëœ ë¶€ë¶„ì„ ìˆ˜ì •í•©ë‹ˆë‹¤.
        
        Args:
            steps: ì›ë³¸ ê³„íš ë‹¨ê³„ë“¤
            
        Returns:
            ê²€ì¦ ë° ìˆ˜ì •ëœ ê³„íš ë‹¨ê³„ë“¤
        """
        validated_steps = []
        
        for step in steps:
            validated_step = step.copy()
            arguments = step.get("arguments", {})
            
            # arguments ë‚´ì˜ ì˜ëª»ëœ í”Œë ˆì´ìŠ¤í™€ë” ê°ì§€ ë° ìˆ˜ì •
            fixed_arguments = {}
            for key, value in arguments.items():
                if isinstance(value, str) and self._is_malformed_argument_value(value):
                    fixed_value = self._fix_malformed_argument_value(value, key, step.get("step", 0))
                    fixed_arguments[key] = fixed_value
                    self.output_manager.log_if_debug(
                        f"ğŸ”§ ê³„íš ìˆ˜ì •: '{value}' -> '{fixed_value}'"
                    )
                else:
                    fixed_arguments[key] = value
            
            validated_step["arguments"] = fixed_arguments
            validated_steps.append(validated_step)
        
        return validated_steps

    def _is_malformed_argument_value(self, value: str) -> bool:
        """ì¸ìˆ˜ ê°’ì´ ì˜ëª»ëœ í˜•íƒœì¸ì§€ ê²€ì‚¬ (ë²”ìš©ì  íŒ¨í„´)"""
        malformed_patterns = [
            "ì´ì „ ë‹¨ê³„",
            "ì•ì„œ",
            "step_\\d+ì˜",
            "ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ",
            "ê¸°ì¤€ìœ¼ë¡œ"
        ]
        return any(re.search(pattern, value) for pattern in malformed_patterns)

    def _fix_malformed_argument_value(self, value: str, key: str, step_num: int) -> str:
        """ì˜ëª»ëœ ì¸ìˆ˜ ê°’ì„ ì˜¬ë°”ë¥¸ í”Œë ˆì´ìŠ¤í™€ë”ë¡œ ìˆ˜ì • (ë²”ìš©ì  ë¡œì§)"""
        # 1. ë‹¨ê³„ ë²ˆí˜¸ê°€ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰ëœ ê²½ìš°
        step_mentions = re.findall(r'step[_\s]*(\d+)', value.lower())
        if step_mentions:
            mentioned_step = step_mentions[-1]  # ë§ˆì§€ë§‰ì— ì–¸ê¸‰ëœ ë‹¨ê³„ ì‚¬ìš©
            return f"$step_{mentioned_step}"
        
        # 2. ê¸°ë³¸ íœ´ë¦¬ìŠ¤í‹±: ì´ì „ ë‹¨ê³„ ì°¸ì¡°
        prev_step = max(1, step_num - 1)
        return f"$step_{prev_step}"
