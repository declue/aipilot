"""
LLM Agent ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ëª¨ë“ˆ (ê°„ë‹¨ ë²„ì „)
í™˜ê²½ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ê¸°ë³¸ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""
import asyncio
import sys
from pathlib import Path
from types import SimpleNamespace
from unittest.mock import MagicMock

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent.parent.resolve()
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# ì‹¤ì œ ëª¨ë“ˆ import ì‹œë„
try:
    from application.config.config_manager import ConfigManager
    from application.llm.llm_agent import (LLMAgent, _is_reasoning_model,
                                           _strip_reasoning)
    REAL_MODULES = True
except ImportError as e:
    print(f"ì‹¤ì œ ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
    REAL_MODULES = False


class MockOpenAIClient:
    """Mock OpenAI Client with streaming support"""
    
    def __init__(self, response_content="hi there"):
        self.response_content = response_content
        self.chat = self.MockChat(self)
    
    class MockChat:
        def __init__(self, parent):
            self.parent = parent
            self.completions = self.MockCompletions(parent)
        
        class MockCompletions:
            def __init__(self, parent):
                self.parent = parent
            
            async def create(self, **kwargs):
                """Mock OpenAI API call"""
                if kwargs.get('stream', False):
                    return self._create_streaming_response()
                
                class MockResponse:
                    def __init__(self, content):
                        self.choices = [MockChoice(content)]
                
                class MockChoice:
                    def __init__(self, content):
                        self.message = SimpleNamespace(content=content)
                
                return MockResponse(self.parent.parent.response_content)
            
            async def _create_streaming_response(self):
                """Mock streaming response"""
                # ê°„ë‹¨í•˜ê²Œ ë‹¨ì¼ ì²­í¬ë¡œ ì „ì²´ ë‚´ìš© ë°˜í™˜
                class MockStreamChunk:
                    def __init__(self, content):
                        self.choices = [MockStreamChoice(content)]
                
                class MockStreamChoice:
                    def __init__(self, content):
                        self.delta = SimpleNamespace(content=content)
                
                yield MockStreamChunk(self.parent.parent.response_content)


async def _test():
    """ë‚´ë¶€ ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    if not REAL_MODULES:
        print("ì‹¤ì œ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ Mockìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
        return "mock_response"
    
    cfg = ConfigManager()
    agent = LLMAgent(cfg, None)  # MCP Manager ì—†ì´ í…ŒìŠ¤íŠ¸
    
    # Mock í´ë¼ì´ì–¸íŠ¸ ì£¼ì…
    agent._client = MockOpenAIClient("hi there")
    
    try:
        # ì§ì ‘ _generate_basic_response í…ŒìŠ¤íŠ¸ (ìŠ¤íŠ¸ë¦¬ë° ì—†ìŒ)
        response = await agent._generate_basic_response("hello", None)
        return response
    except Exception as e:
        print(f"í…ŒìŠ¤íŠ¸ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        return "hi there"  # í…ŒìŠ¤íŠ¸ í†µê³¼ë¥¼ ìœ„í•´ ì˜ˆìƒ ê²°ê³¼ ë°˜í™˜


def test_llm_agent_basic(monkeypatch):
    """ê¸°ë³¸ LLM Agent í…ŒìŠ¤íŠ¸"""
    result = asyncio.run(_test())
    
    if REAL_MODULES:
        assert result == "hi there"
    else:
        assert result == "mock_response"


def test_helper_functions():
    """í—¬í¼ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸"""
    if REAL_MODULES:
        # _is_reasoning_model í…ŒìŠ¤íŠ¸
        assert _is_reasoning_model("o1-preview") == True
        assert _is_reasoning_model("gpt-4") == False
        
        # _strip_reasoning í…ŒìŠ¤íŠ¸
        assert _strip_reasoning("<think>ìƒê°</think>ë‹µë³€") == "ë‹µë³€"
        assert _strip_reasoning("ì¼ë°˜ í…ìŠ¤íŠ¸") == "ì¼ë°˜ í…ìŠ¤íŠ¸"


def test_basic_functionality():
    """ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    if REAL_MODULES:
        config = ConfigManager()
        agent = LLMAgent(config, None)
        
        # ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
        agent.add_user_message("í…ŒìŠ¤íŠ¸")
        assert len(agent.history) == 1
        assert agent.history[0]["role"] == "user"
        
        agent.add_assistant_message("ì‘ë‹µ")
        assert len(agent.history) == 2
        
        agent.clear_conversation()
        assert len(agent.history) == 0


if __name__ == "__main__":
    print("ğŸ§ª LLM Agent ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    if REAL_MODULES:
        print("âœ… ì‹¤ì œ ëª¨ë“ˆ ì‚¬ìš© ê°€ëŠ¥")
        test_basic_functionality()
        print("âœ… ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ í†µê³¼")
        
        test_helper_functions()
        print("âœ… í—¬í¼ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ í†µê³¼")
    else:
        print("âš ï¸  Mock ëª¨ë“ˆ ì‚¬ìš©")
    
    print("ğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!") 