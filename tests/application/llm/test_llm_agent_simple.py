"""
LLM Agent ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ëª¨ë“ˆ
í™˜ê²½ ë¬¸ì œ ì—†ì´ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ìµœì†Œí•œì˜ í…ŒìŠ¤íŠ¸
"""
import asyncio
import sys
from pathlib import Path
from types import SimpleNamespace
from typing import Any, Dict, Optional
from unittest.mock import MagicMock

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent.parent.resolve()
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

try:
    from application.config.config_manager import ConfigManager
    from application.llm.llm_agent import LLMAgent
    MODULES_AVAILABLE = True
except ImportError:
    MODULES_AVAILABLE = False
    
    # ê°„ë‹¨í•œ Mock í´ë˜ìŠ¤ë“¤
    class ConfigManager:  # type: ignore
        def get_llm_config(self) -> Dict[str, Any]:
            return {
                "api_key": "test-key",
                "base_url": "http://test-url",
                "model": "test-model",
                "max_tokens": 1000,
                "temperature": 0.7,
                "show_cot": "false"
            }
        
        def get_config_value(self, section: str, key: str, default: Any = None) -> Any:
            return default
    
    class LLMAgent:  # type: ignore
        def __init__(self, config_manager: Any, mcp_tool_manager: Any) -> None:
            self.config_manager = config_manager
            self.mcp_tool_manager = mcp_tool_manager
            self.history: list[Dict[str, str]] = []
            self._client = None
        
        def add_user_message(self, text: str) -> None:
            self.history.append({"role": "user", "content": text})
        
        def add_assistant_message(self, text: str) -> None:
            self.history.append({"role": "assistant", "content": text})
        
        def clear_conversation(self) -> None:
            self.history.clear()
        
        async def generate_response(self, user_message: str) -> str:
            self.add_user_message(user_message)
            response = "Test response"
            self.add_assistant_message(response)
            return response


class SimpleOpenAIClient:
    """ê°€ì¥ ê°„ë‹¨í•œ OpenAI í´ë¼ì´ì–¸íŠ¸ ëª¨í‚¹"""
    
    def __init__(self, response_content: str = "hi there") -> None:
        self.response_content = response_content
        self.chat = self.Chat(self)
    
    class Chat:
        def __init__(self, parent: Any) -> None:
            self.parent = parent
            self.completions = self.Completions(parent)
        
        class Completions:
            def __init__(self, parent: Any) -> None:
                self.parent = parent
            
            async def create(self, **kwargs: Any) -> Any:
                class Response:
                    def __init__(self, content: str) -> None:
                        self.choices = [Choice(content)]
                
                class Choice:
                    def __init__(self, content: str) -> None:
                        self.message = SimpleNamespace(content=content)
                
                return Response(self.parent.parent.response_content)


def test_llm_agent_basic_functionality() -> None:
    """LLM Agent ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    config = ConfigManager()
    agent = LLMAgent(config, None)  # type: ignore
    
    # ì´ˆê¸° ìƒíƒœ í™•ì¸
    assert agent.config_manager == config
    assert agent.mcp_tool_manager is None
    assert agent.history == []
    
    # ë©”ì‹œì§€ ì¶”ê°€ í…ŒìŠ¤íŠ¸
    agent.add_user_message("Hello")
    assert len(agent.history) == 1
    assert agent.history[0]["role"] == "user"
    assert agent.history[0]["content"] == "Hello"
    
    agent.add_assistant_message("Hi there")
    assert len(agent.history) == 2
    assert agent.history[1]["role"] == "assistant"
    assert agent.history[1]["content"] == "Hi there"
    
    # ëŒ€í™” ì‚­ì œ í…ŒìŠ¤íŠ¸
    agent.clear_conversation()
    assert len(agent.history) == 0


async def test_llm_agent_response_generation() -> None:
    """LLM Agent ì‘ë‹µ ìƒì„± í…ŒìŠ¤íŠ¸"""
    config = ConfigManager()
    agent = LLMAgent(config, None)  # type: ignore
    
    # í´ë¼ì´ì–¸íŠ¸ ëª¨í‚¹
    agent._client = SimpleOpenAIClient("Test response")  # type: ignore
    
    response = await agent.generate_response("Hello")
    
    if MODULES_AVAILABLE:
        # ì‹¤ì œ ëª¨ë“ˆì´ ìˆëŠ” ê²½ìš°, ì‹¤ì œ ì‘ë‹µ í™•ì¸
        assert isinstance(response, str)
        assert len(response) > 0
    else:
        # Mockì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°
        assert response == "Test response"
    
    # íˆìŠ¤í† ë¦¬ í™•ì¸
    assert len(agent.history) == 2
    assert agent.history[0]["content"] == "Hello"


def test_llm_agent_multiple_messages() -> None:
    """ì—¬ëŸ¬ ë©”ì‹œì§€ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    config = ConfigManager()
    agent = LLMAgent(config, None)  # type: ignore
    
    # ì—¬ëŸ¬ ë©”ì‹œì§€ ì¶”ê°€
    messages = ["First", "Second", "Third"]
    for msg in messages:
        agent.add_user_message(msg)
        agent.add_assistant_message(f"Response to {msg}")
    
    assert len(agent.history) == 6
    
    # ë‚´ìš© í™•ì¸
    for i, msg in enumerate(messages):
        assert agent.history[i*2]["content"] == msg
        assert agent.history[i*2+1]["content"] == f"Response to {msg}"


def test_llm_agent_edge_cases() -> None:
    """ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸"""
    config = ConfigManager()
    agent = LLMAgent(config, None)  # type: ignore
    
    # ë¹ˆ ë¬¸ìì—´ ì²˜ë¦¬
    agent.add_user_message("")
    agent.add_assistant_message("")
    assert len(agent.history) == 2
    assert agent.history[0]["content"] == ""
    assert agent.history[1]["content"] == ""
    
    # ë§¤ìš° ê¸´ ë©”ì‹œì§€
    long_message = "x" * 10000
    agent.add_user_message(long_message)
    assert agent.history[-1]["content"] == long_message
    
    # íŠ¹ìˆ˜ ë¬¸ì
    special_message = "!@#$%^&*()_+"
    agent.add_assistant_message(special_message)
    assert agent.history[-1]["content"] == special_message


def run_async_test() -> None:
    """ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    asyncio.run(test_llm_agent_response_generation())


if __name__ == "__main__":
    print("LLM Agent ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰...")
    
    test_llm_agent_basic_functionality()
    print("âœ… ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ í†µê³¼")
    
    run_async_test()
    print("âœ… ì‘ë‹µ ìƒì„± í…ŒìŠ¤íŠ¸ í†µê³¼")
    
    test_llm_agent_multiple_messages()
    print("âœ… ë‹¤ì¤‘ ë©”ì‹œì§€ í…ŒìŠ¤íŠ¸ í†µê³¼")
    
    test_llm_agent_edge_cases()
    print("âœ… ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸ í†µê³¼")
    
    print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! LLM Agent ê¸°ë³¸ ê¸°ëŠ¥ì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.") 