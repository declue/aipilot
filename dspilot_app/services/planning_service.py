"""
DSPilot CLI ê³„íš ìˆ˜ë¦½ ì„œë¹„ìŠ¤ (PlanningService)
============================================

ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ **ExecutionPlan(JSON)** ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì»´í¬ë„ŒíŠ¸ì…ë‹ˆë‹¤.
LangChain í˜¸í™˜ MCP Tool ë©”íƒ€ë°ì´í„°ë¥¼ LLM ì— ì „ë‹¬í•˜ê³ , ì‘ë‹µì—ì„œ JSON ê³„íšì„
ì¶”ì¶œÂ·ê²€ì¦í•œ ë’¤ `ExecutionManager` ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
"""

import json
import logging
import re
from typing import Any, Dict, List, Optional

import dspilot_core.instructions.prompt_manager as prompt_manager
from dspilot_app.services.models.execution_plan import ExecutionPlan, ExecutionStep
from dspilot_core.llm.agents.base_agent import BaseAgent
from dspilot_core.llm.mcp.mcp_tool_manager import MCPToolManager
from dspilot_core.llm.models.conversation_message import ConversationMessage
from dspilot_core.llm.workflow import get_workflow

logger = logging.getLogger(__name__)


class PromptNames:
    """í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì´ë¦„ ìƒìˆ˜"""

    ANALYSIS = "analysis_prompts"
    FINAL_ANALYSIS = "final_analysis_prompts"
    ENHANCED = "enhanced_prompts"


class PlanningService:
    """ìš”ì²­ ë¶„ì„ ë° ì‹¤í–‰ ê³„íš ìˆ˜ë¦½ì„ ë‹´ë‹¹í•˜ëŠ” ì„œë¹„ìŠ¤"""

    def __init__(self, llm_agent: BaseAgent, mcp_tool_manager: MCPToolManager) -> None:
        """
        ê³„íš ìˆ˜ë¦½ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”

        Args:
            llm_agent: LLM ì—ì´ì „íŠ¸
            mcp_tool_manager: MCP ë„êµ¬ ê´€ë¦¬ì
        """
        self.llm_agent = llm_agent
        self.mcp_tool_manager = mcp_tool_manager
        self.prompt_manager = prompt_manager.get_default_prompt_manager()

    async def analyze_request_and_plan(self, user_message: str) -> Optional[ExecutionPlan]:
        """
        ìš”ì²­ ë¶„ì„ ë° ì‹¤í–‰ ê³„íš ìˆ˜ë¦½

        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€

        Returns:
            ì‹¤í–‰ ê³„íš (ë„êµ¬ê°€ í•„ìš”í•˜ì§€ ì•Šê±°ë‚˜ ì›Œí¬í”Œë¡œìš°ë¡œ ì²˜ë¦¬ëœ ê²½ìš° None)
        """
        try:
            # 1. ì›Œí¬í”Œë¡œìš° íŒ¨í„´ ê°ì§€ ë° ë¶„ê¸°
            workflow_result = await self._detect_and_execute_workflow(user_message)
            if workflow_result is not None:
                # ì›Œí¬í”Œë¡œìš°ê°€ ì§ì ‘ ì²˜ë¦¬í•œ ê²½ìš°, ì‹¤í–‰ ê³„íš ë¶ˆí•„ìš”
                logger.debug("ì›Œí¬í”Œë¡œìš°ê°€ ìš”ì²­ì„ ì§ì ‘ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.")
                return None

            # 2. ì¼ë°˜ì ì¸ ë„êµ¬ ì‹¤í–‰ ê³„íš ìˆ˜ë¦½
            return await self._create_standard_execution_plan(user_message)

        except Exception as e:
            logger.warning(f"ê³„íš ìˆ˜ë¦½ ì‹¤íŒ¨: {e}")
            return None

    async def _detect_and_execute_workflow(self, user_message: str) -> Optional[str]:
        """
        ì›Œí¬í”Œë¡œìš° íŒ¨í„´ì„ ê°ì§€í•˜ê³  í•´ë‹¹ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€

        Returns:
            ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ê²°ê³¼ (íŒ¨í„´ì´ ê°ì§€ë˜ì§€ ì•Šìœ¼ë©´ None)
        """
        # ì½”ë“œ ìˆ˜ì • íŒ¨í„´ ê°ì§€
        # 1. ì½”ë“œ ìˆ˜ì • íŒ¨í„´ ê°ì§€ ë° ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        if await self._is_code_modification_request(user_message):
            logger.debug("ì½”ë“œ ìˆ˜ì • íŒ¨í„´ ê°ì§€, CodeModificationWorkflow ì‹¤í–‰")

            def streaming_callback(content: str) -> None:
                logger.debug(f"[ì›Œí¬í”Œë¡œìš°] {content.strip()}")

            try:
                workflow_class = get_workflow("code_mod")
                workflow = workflow_class()
                result = await workflow.run(self.llm_agent, user_message, streaming_callback)
                logger.debug(f"ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì™„ë£Œ: {result}")
                return result
            except Exception as e:
                logger.error(f"ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                return None

        # 2. ë¦¬ì„œì¹˜/ê²€ìƒ‰ íŒ¨í„´ ê°ì§€ ë° ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        if await self._is_research_request(user_message):
            logger.debug("ë¦¬ì„œì¹˜ íŒ¨í„´ ê°ì§€, ResearchWorkflow ì‹¤í–‰")

            def research_streaming_callback(content: str) -> None:
                logger.debug(f"[ì›Œí¬í”Œë¡œìš°] {content.strip()}")

            try:
                workflow_class = get_workflow("research")
                workflow = workflow_class()
                result = await workflow.run(self.llm_agent, user_message, research_streaming_callback)
                logger.debug(f"ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì™„ë£Œ: {result}")
                return result
            except Exception as e:
                logger.error(f"ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                return None

        return None

    async def _is_code_modification_request(self, user_message: str) -> bool:
        """
        ì½”ë“œ ìˆ˜ì • ìš”ì²­ì¸ì§€ íŒë‹¨í•©ë‹ˆë‹¤.

        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€

        Returns:
            ì½”ë“œ ìˆ˜ì • ìš”ì²­ ì—¬ë¶€
        """
        code_modification_keywords = [
            "ìˆ˜ì •", "ë³€ê²½", "ê³ ì¹˜", "ë°”ê¾¸", "ê°œì„ ", "ë¦¬íŒ©í† ë§", "refactor",
            "modify", "change", "update", "fix", "edit", "íŒŒì¼ ìˆ˜ì •", "ì½”ë“œ ìˆ˜ì •",
        ]

        file_extension_keywords = [
            ".py", ".js", ".ts", ".java", ".cpp", ".c", ".go", ".rs", ".rb", ".php",
        ]

        message_lower = user_message.lower()
        has_modification_keyword = any(keyword in message_lower for keyword in code_modification_keywords)
        has_file_reference = any(ext in message_lower for ext in file_extension_keywords)

        file_path_pattern = r"[\w\-\.\/\\]+\.\w{2,4}"
        has_file_path = bool(re.search(file_path_pattern, user_message))

        return has_modification_keyword and (has_file_reference or has_file_path)

    async def _is_research_request(self, user_message: str) -> bool:
        """
        ë¦¬ì„œì¹˜/ê²€ìƒ‰ ìš”ì²­ì¸ì§€ íŒë‹¨í•©ë‹ˆë‹¤.

        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€

        Returns:
            ë¦¬ì„œì¹˜ ìš”ì²­ ì—¬ë¶€
        """
        research_keywords = [
            "ê²€ìƒ‰", "ì°¾ì•„", "ì•Œì•„ë´", "ì¡°ì‚¬", "ë¦¬ì„œì¹˜", "research", "search",
            "ë‰´ìŠ¤", "ì •ë³´", "ë™í–¥", "íŠ¸ë Œë“œ", "í˜„í™©", "ë¶„ì„", "ìš”ì•½",
        ]

        comprehensive_keywords = [
            "ìš”ì•½í•´ì„œ", "ì •ë¦¬í•´ì„œ", "íŒŒì¼ë¡œ ì €ì¥", "ë¸”ë¡œê·¸", "ë³´ê³ ì„œ",
            "ì •ë¦¬ëœ ë‚´ìš©", "ì¢…í•©", "ì·¨í•©",
        ]

        time_keywords = ["ìµœì‹ ", "ì–´ì œ", "ì˜¤ëŠ˜", "ì´ë²ˆì£¼", "ìµœê·¼", "latest", "recent"]

        message_lower = user_message.lower()
        has_research_keyword = any(keyword in message_lower for keyword in research_keywords)
        has_comprehensive_keyword = any(keyword in message_lower for keyword in comprehensive_keywords)
        has_time_keyword = any(keyword in message_lower for keyword in time_keywords)

        return has_research_keyword and (has_comprehensive_keyword or has_time_keyword)

    async def _create_standard_execution_plan(self, user_message: str) -> Optional[ExecutionPlan]:
        """
        í‘œì¤€ ì‹¤í–‰ ê³„íšì„ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€

        Returns:
            ì‹¤í–‰ ê³„íš (ë„êµ¬ê°€ í•„ìš”í•˜ì§€ ì•Šìœ¼ë©´ None)
        """
        available_tools = await self._get_available_tools()
        if not available_tools:
            return None

        tool_lines = []
        for tool in available_tools:
            param_fields = getattr(tool, "args", None) or getattr(tool, "args_schema", None)
            param_names: List[str] = []
            if param_fields:
                try:
                    param_names = list(param_fields.__fields__.keys())
                except Exception:
                    param_names = list(param_fields.keys()) if isinstance(param_fields, dict) else []

            params_str = f"({', '.join(param_names)})" if param_names else ""
            tool_lines.append(f"- {tool.name}{params_str}: {tool.description}")

        tools_desc = "\n".join(tool_lines)

        analysis_prompt = self.prompt_manager.get_formatted_prompt(
            PromptNames.ANALYSIS, user_message=user_message, tools_desc=tools_desc
        )

        if analysis_prompt is None:
            logger.error("ë¶„ì„ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨")
            return None

        context = [ConversationMessage(role="user", content=analysis_prompt)]
        response = await self.llm_agent.llm_service.generate_response(context)

        logger.debug(
            f"[LLM-RAW-PLAN] {response.response[:500].replace('\n', ' ') if isinstance(response.response, str) else str(response)[:500]}"
        )

        plan_data = self._parse_plan_response(response.response)
        if plan_data and plan_data.get("need_tools", False):
            valid_tool_names = {tool.name for tool in available_tools}
            raw_plan = plan_data.get("plan", {})
            if not raw_plan or not raw_plan.get("steps"):
                return None

            filtered_steps = [
                s for s in raw_plan.get("steps", []) if s.get("tool_name") in valid_tool_names
            ]

            if not filtered_steps:
                return None

            filtered_steps.sort(key=lambda s: s.get("step", 0))

            validated_steps = self._validate_and_fix_plan_steps(filtered_steps)
            raw_plan["steps"] = validated_steps

            execution_plan = self._create_execution_plan(raw_plan)
            if execution_plan and execution_plan.steps:
                return execution_plan

        return None

    async def _get_available_tools(self) -> List[Any]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        available_tools = []
        if self.mcp_tool_manager and hasattr(self.mcp_tool_manager, "get_langchain_tools"):
            try:
                available_tools = await self.mcp_tool_manager.get_langchain_tools()
            except Exception as e:
                logger.warning(f"ë„êµ¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return available_tools

    def _parse_plan_response(self, response_text: str) -> Optional[Dict[str, Any]]:
        """ì‘ë‹µì—ì„œ JSON ê³„íš íŒŒì‹±"""
        try:
            start_idx = response_text.find("{")
            end_idx = response_text.rfind("}") + 1
            if start_idx != -1 and end_idx != 0:
                json_str = response_text[start_idx:end_idx]
                result: Dict[str, Any] = json.loads(json_str)
                return result
        except (json.JSONDecodeError, ValueError):
            pass
        return None

    def _create_execution_plan(self, plan_data: Dict[str, Any]) -> ExecutionPlan:
        """
        ê³„íš ë°ì´í„°ë¡œë¶€í„° ExecutionPlan ê°ì²´ ìƒì„±
        """
        steps = []
        for step_data in plan_data.get("steps", []):
            step = ExecutionStep(
                step=step_data.get("step", 0),
                description=step_data.get("description", ""),
                tool_name=step_data.get("tool_name", ""),
                arguments=step_data.get("arguments", {}),
                confirm_message=step_data.get("confirm_message", ""),
            )
            steps.append(step)

        return ExecutionPlan(
            description=plan_data.get("description", "ë„êµ¬ ì‹¤í–‰ ê³„íš"), steps=steps
        )

    def _validate_and_fix_plan_steps(self, steps: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ê³„íš ë‹¨ê³„ë“¤ì„ ê²€ì¦í•˜ê³  ì˜ëª»ëœ ë¶€ë¶„ì„ ìˆ˜ì •í•©ë‹ˆë‹¤.
        """
        validated_steps = []

        for step in steps:
            validated_step = step.copy()
            arguments = step.get("arguments", {})

            fixed_arguments = {}
            for key, value in arguments.items():
                if isinstance(value, str) and self._is_malformed_argument_value(value):
                    fixed_value = self._fix_malformed_argument_value(value, key, step.get("step", 0))
                    logger.debug(f"ğŸ”§ ê³„íš ìˆ˜ì •: '{value}' -> '{fixed_value}'")
                    fixed_arguments[key] = fixed_value
                else:
                    fixed_arguments[key] = value

            validated_step["arguments"] = fixed_arguments
            validated_steps.append(validated_step)

        return validated_steps

    def _is_malformed_argument_value(self, value: str) -> bool:
        """ì¸ìˆ˜ ê°’ì´ ì˜ëª»ëœ í˜•íƒœì¸ì§€ ê²€ì‚¬"""
        malformed_patterns = ["ì´ì „ ë‹¨ê³„", "ì•ì„œ", "step_\\d+ì˜", "ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ", "ê¸°ì¤€ìœ¼ë¡œ"]
        return any(re.search(pattern, value) for pattern in malformed_patterns)

    def _fix_malformed_argument_value(self, value: str, key: str, step_num: int) -> str:
        """ì˜ëª»ëœ ì¸ìˆ˜ ê°’ì„ ì˜¬ë°”ë¥¸ í”Œë ˆì´ìŠ¤í™€ë”ë¡œ ìˆ˜ì •"""
        step_mentions = re.findall(r"step[_\s]*(\d+)", value.lower())
        if step_mentions:
            mentioned_step = step_mentions[-1]
            return f"$step_{mentioned_step}"

        prev_step = max(1, step_num - 1)
        return f"$step_{prev_step}"
